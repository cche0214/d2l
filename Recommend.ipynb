{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a7be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae5b837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0   196   242       3  881250949\n",
       "1   186   302       3  891717742\n",
       "2    22   377       1  878887116\n",
       "3   244    51       2  880606923\n",
       "4   166   346       1  886397596"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"ml-100k/u.data\",\n",
    "    sep = \"\\t\",\n",
    "    names = [\"user\", \"item\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a3f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据条数： 100000\n",
      "用户数量： 943\n",
      "物品数量： 1682\n"
     ]
    }
   ],
   "source": [
    "print(\"数据条数：\", len(data))\n",
    "# 这里是nunique()\n",
    "print(\"用户数量：\", data[\"user\"].nunique())\n",
    "print(\"物品数量：\", data[\"item\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d27533",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"user\"] -= 1\n",
    "data[\"item\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dba37ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59972</th>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>874965478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92487</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>874965478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74577</th>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "      <td>874965518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48214</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>874965556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15764</th>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>5</td>\n",
       "      <td>874965677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93377</th>\n",
       "      <td>942</td>\n",
       "      <td>448</td>\n",
       "      <td>1</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94914</th>\n",
       "      <td>942</td>\n",
       "      <td>228</td>\n",
       "      <td>2</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95003</th>\n",
       "      <td>942</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95291</th>\n",
       "      <td>942</td>\n",
       "      <td>227</td>\n",
       "      <td>3</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92880</th>\n",
       "      <td>942</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>888693184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating  timestamp\n",
       "59972     0   167       5  874965478\n",
       "92487     0   171       5  874965478\n",
       "74577     0   164       5  874965518\n",
       "48214     0   155       4  874965556\n",
       "15764     0   195       5  874965677\n",
       "...     ...   ...     ...        ...\n",
       "93377   942   448       1  888693158\n",
       "94914   942   228       2  888693158\n",
       "95003   942   229       1  888693158\n",
       "95291   942   227       3  888693158\n",
       "92880   942   233       3  888693184\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=[\"user\", \"timestamp\"])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a75bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们需要给每个用户学习一个向量，给每个物品学习一个向量\n",
    "# 所以需要给两个东西进行embedding操作，这种操作本质是一个查表操作\n",
    "# 由于nn.embedding里面的矩阵索引从0开始，所以我们要把用户和物品的序号也从0开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd50c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "# groupby按某一列分组，得到一个小的DataFrame\n",
    "# {\n",
    "#   0: DataFrame(两行)\n",
    "#   1: DataFrame(两行)\n",
    "# }\n",
    "for user, group in data.groupby(\"user\"):\n",
    "    group = group.sort_values(\"timestamp\")\n",
    "    \n",
    "    # 这个是单行\n",
    "    test_interaction = group.iloc[-1]     # 最后一个给测试\n",
    "    # 这个是DataFrame\n",
    "    train_interactions = group.iloc[:-1]  # 其他给训练\n",
    "    \n",
    "    test_list.append(test_interaction)\n",
    "    train_list.append(train_interactions)\n",
    "\n",
    "# 所以拼接方式不同\n",
    "train_data = pd.concat(train_list)\n",
    "test_data = pd.DataFrame(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47276935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59972</th>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "      <td>874965478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92487</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>874965478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74577</th>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "      <td>874965518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48214</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>874965556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22971</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>5</td>\n",
       "      <td>874965677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92536</th>\n",
       "      <td>942</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93377</th>\n",
       "      <td>942</td>\n",
       "      <td>448</td>\n",
       "      <td>1</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94914</th>\n",
       "      <td>942</td>\n",
       "      <td>228</td>\n",
       "      <td>2</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95003</th>\n",
       "      <td>942</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95291</th>\n",
       "      <td>942</td>\n",
       "      <td>227</td>\n",
       "      <td>3</td>\n",
       "      <td>888693158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99057 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating  timestamp\n",
       "59972     0   167       5  874965478\n",
       "92487     0   171       5  874965478\n",
       "74577     0   164       5  874965518\n",
       "48214     0   155       4  874965556\n",
       "22971     0   165       5  874965677\n",
       "...     ...   ...     ...        ...\n",
       "92536   942   226       1  888693158\n",
       "93377   942   448       1  888693158\n",
       "94914   942   228       2  888693158\n",
       "95003   942   229       1  888693158\n",
       "95291   942   227       3  888693158\n",
       "\n",
       "[99057 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b9a54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19699</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>889751736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>888980240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37188</th>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>889237482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48826</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>892004520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32177</th>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>2</td>\n",
       "      <td>879198898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94676</th>\n",
       "      <td>938</td>\n",
       "      <td>253</td>\n",
       "      <td>3</td>\n",
       "      <td>880262319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82942</th>\n",
       "      <td>939</td>\n",
       "      <td>315</td>\n",
       "      <td>4</td>\n",
       "      <td>889480582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98516</th>\n",
       "      <td>940</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>875049144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88898</th>\n",
       "      <td>941</td>\n",
       "      <td>661</td>\n",
       "      <td>4</td>\n",
       "      <td>891283517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92880</th>\n",
       "      <td>942</td>\n",
       "      <td>233</td>\n",
       "      <td>3</td>\n",
       "      <td>888693184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating  timestamp\n",
       "19699     0   101       2  889751736\n",
       "7519      1   280       3  888980240\n",
       "37188     2   180       4  889237482\n",
       "48826     3    10       4  892004520\n",
       "32177     4   394       2  879198898\n",
       "...     ...   ...     ...        ...\n",
       "94676   938   253       3  880262319\n",
       "82942   939   315       4  889480582\n",
       "98516   940     0       5  875049144\n",
       "88898   941   661       4  891283517\n",
       "92880   942   233       3  888693184\n",
       "\n",
       "[943 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"user 最小值：\", data[\"user\"].min())\n",
    "print(\"user 最大值：\", data[\"user\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"item 最小值：\", data[\"item\"].min())\n",
    "print(\"item 最大值：\", data[\"item\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ddc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 他们的下标都没有从0开始，超出索引范围所以要减1\n",
    "data[\"user\"] -= 1\n",
    "data[\"item\"] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"user 最小值：\", data[\"user\"].min())\n",
    "print(\"user 最大值：\", data[\"user\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"item 最小值：\", data[\"item\"].min())\n",
    "print(\"item 最大值：\", data[\"item\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af648c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = data[\"item\"].nunique()\n",
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2109e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推荐系统必须把数据变成结构化形式，上面只是记录了交互，需要构建用户的交互矩阵\n",
    "# 比如我们需要知道每个用户看过什么电影，用来构建负样本的采样\n",
    "# 从用户行为日志构建用户兴趣集合\n",
    "user_pos_items = {}\n",
    "\n",
    "for user, item in zip(train_data[\"user\"], train_data[\"item\"]):\n",
    "    if user not in user_pos_items:\n",
    "        user_pos_items[user] = set()\n",
    "    user_pos_items[user].add(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4161fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"用户数量：\", len(user_pos_items))\n",
    "print(\"用户0看过的电影数量：\", len(user_pos_items[0]))\n",
    "# 因为set是一个无序的集合，所以切片要变成list\n",
    "print(\"用户0看过的前十个电影：\", list(user_pos_items[0])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b82057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1679, 943)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = train_data[\"user\"].nunique()\n",
    "num_items = train_data[\"item\"].nunique()\n",
    "num_items, num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1520ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从user_pos_items生成负样本，也就是变成(u, i, j)\n",
    "# u是用户，i是他看过的，j是他没看过的\n",
    "import random\n",
    "import torch\n",
    "\n",
    "num_items = data[\"item\"].nunique()\n",
    "\n",
    "def generate_train_data(user_pos_items, num_items):\n",
    "    users = []\n",
    "    pos_items = []\n",
    "    neg_items = []\n",
    "\n",
    "    for user in user_pos_items:\n",
    "        for pos_item in user_pos_items[user]:\n",
    "\n",
    "            # 随机采负样本\n",
    "            # 这个和range还不一样，这个是左闭右闭的\n",
    "            neg_item = random.randint(0, num_items - 1)\n",
    "\n",
    "            # 如果采到了正样本，重新采\n",
    "            while neg_item in user_pos_items[user]:\n",
    "                neg_item = random.randint(0, num_items - 1)\n",
    "\n",
    "            users.append(user)\n",
    "            pos_items.append(pos_item)\n",
    "            neg_items.append(neg_item)\n",
    "\n",
    "    # PyTorch的tensor有数据类型，LongTensor是int64 tensor\n",
    "    return torch.LongTensor(users), torch.LongTensor(pos_items), torch.LongTensor(neg_items)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "718eacd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本数量: 99057\n",
      "示例前三个样本:\n",
      "0 0 1376\n",
      "0 1 655\n",
      "0 2 1222\n"
     ]
    }
   ],
   "source": [
    "users, pos_items, neg_items = generate_train_data(user_pos_items, num_items)\n",
    "\n",
    "# 100000条是给每个用户的每个看过的电影，搭配一个负样本\n",
    "print(\"训练样本数量:\", len(users))\n",
    "print(\"示例前三个样本:\")\n",
    "for i in range(3):\n",
    "    print(users[i].item(), pos_items[i].item(), neg_items[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e84ff58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim = 64):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding矩阵的维度是[943, 64], [1682, 64]\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        # 传入的是LongTensor，根据embedding矩阵查表\n",
    "        # 返回[100000, 64]，就是给每个样本找他的向量\n",
    "        user_vec = self.user_embedding(users)\n",
    "        item_vec = self.item_embedding(items)\n",
    "        # 这里不是矩阵乘法，这里是逐元素乘法，返回的依旧是[100000, 64]\n",
    "        # user_vec[0] = [a1,a2,...,a64]\n",
    "        # item_vec[0] = [b1,b2,...,b64]\n",
    "        # [a1b1, a2b2, ..., a64b64]\n",
    "        # 然后按列降维，变成[100000]，就表示每一个样本对这个物品的评分\n",
    "        scores = (user_vec * item_vec).sum(dim=1)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c29bbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = data[\"user\"].nunique()\n",
    "num_items = data[\"item\"].nunique()\n",
    "print(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30385821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a795d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(num_users, num_items, embedding_dim = 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2278d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPR损失\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    return -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8958883",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "253b1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.4567\n",
      "Epoch 1, Loss: 3.8707\n",
      "Epoch 2, Loss: 3.4160\n",
      "Epoch 3, Loss: 2.9949\n",
      "Epoch 4, Loss: 2.5440\n",
      "Epoch 5, Loss: 2.1248\n",
      "Epoch 6, Loss: 1.6931\n",
      "Epoch 7, Loss: 1.3508\n",
      "Epoch 8, Loss: 1.0475\n",
      "Epoch 9, Loss: 0.8573\n",
      "Epoch 10, Loss: 0.7073\n",
      "Epoch 11, Loss: 0.6085\n",
      "Epoch 12, Loss: 0.5215\n",
      "Epoch 13, Loss: 0.4725\n",
      "Epoch 14, Loss: 0.4224\n",
      "Epoch 15, Loss: 0.3877\n",
      "Epoch 16, Loss: 0.3493\n",
      "Epoch 17, Loss: 0.3197\n",
      "Epoch 18, Loss: 0.2981\n",
      "Epoch 19, Loss: 0.2765\n",
      "Epoch 20, Loss: 0.2575\n",
      "Epoch 21, Loss: 0.2373\n",
      "Epoch 22, Loss: 0.2201\n",
      "Epoch 23, Loss: 0.2099\n",
      "Epoch 24, Loss: 0.1976\n",
      "Epoch 25, Loss: 0.1879\n",
      "Epoch 26, Loss: 0.1794\n",
      "Epoch 27, Loss: 0.1679\n",
      "Epoch 28, Loss: 0.1613\n",
      "Epoch 29, Loss: 0.1568\n",
      "Epoch 30, Loss: 0.1455\n",
      "Epoch 31, Loss: 0.1425\n",
      "Epoch 32, Loss: 0.1364\n",
      "Epoch 33, Loss: 0.1288\n",
      "Epoch 34, Loss: 0.1245\n",
      "Epoch 35, Loss: 0.1223\n",
      "Epoch 36, Loss: 0.1130\n",
      "Epoch 37, Loss: 0.1117\n",
      "Epoch 38, Loss: 0.1095\n",
      "Epoch 39, Loss: 0.1070\n",
      "Epoch 40, Loss: 0.1048\n",
      "Epoch 41, Loss: 0.0996\n",
      "Epoch 42, Loss: 0.0994\n",
      "Epoch 43, Loss: 0.0935\n",
      "Epoch 44, Loss: 0.0928\n",
      "Epoch 45, Loss: 0.0924\n",
      "Epoch 46, Loss: 0.0908\n",
      "Epoch 47, Loss: 0.0867\n",
      "Epoch 48, Loss: 0.0854\n",
      "Epoch 49, Loss: 0.0837\n",
      "Epoch 50, Loss: 0.0831\n",
      "Epoch 51, Loss: 0.0790\n",
      "Epoch 52, Loss: 0.0807\n",
      "Epoch 53, Loss: 0.0777\n",
      "Epoch 54, Loss: 0.0743\n",
      "Epoch 55, Loss: 0.0749\n",
      "Epoch 56, Loss: 0.0713\n",
      "Epoch 57, Loss: 0.0722\n",
      "Epoch 58, Loss: 0.0677\n",
      "Epoch 59, Loss: 0.0702\n",
      "Epoch 60, Loss: 0.0695\n",
      "Epoch 61, Loss: 0.0684\n",
      "Epoch 62, Loss: 0.0673\n",
      "Epoch 63, Loss: 0.0661\n",
      "Epoch 64, Loss: 0.0644\n",
      "Epoch 65, Loss: 0.0665\n",
      "Epoch 66, Loss: 0.0628\n",
      "Epoch 67, Loss: 0.0629\n",
      "Epoch 68, Loss: 0.0613\n",
      "Epoch 69, Loss: 0.0611\n",
      "Epoch 70, Loss: 0.0586\n",
      "Epoch 71, Loss: 0.0590\n",
      "Epoch 72, Loss: 0.0574\n",
      "Epoch 73, Loss: 0.0575\n",
      "Epoch 74, Loss: 0.0568\n",
      "Epoch 75, Loss: 0.0552\n",
      "Epoch 76, Loss: 0.0555\n",
      "Epoch 77, Loss: 0.0550\n",
      "Epoch 78, Loss: 0.0539\n",
      "Epoch 79, Loss: 0.0543\n",
      "Epoch 80, Loss: 0.0530\n",
      "Epoch 81, Loss: 0.0541\n",
      "Epoch 82, Loss: 0.0524\n",
      "Epoch 83, Loss: 0.0511\n",
      "Epoch 84, Loss: 0.0505\n",
      "Epoch 85, Loss: 0.0510\n",
      "Epoch 86, Loss: 0.0503\n",
      "Epoch 87, Loss: 0.0487\n",
      "Epoch 88, Loss: 0.0511\n",
      "Epoch 89, Loss: 0.0502\n",
      "Epoch 90, Loss: 0.0490\n",
      "Epoch 91, Loss: 0.0467\n",
      "Epoch 92, Loss: 0.0485\n",
      "Epoch 93, Loss: 0.0467\n",
      "Epoch 94, Loss: 0.0469\n",
      "Epoch 95, Loss: 0.0461\n",
      "Epoch 96, Loss: 0.0462\n",
      "Epoch 97, Loss: 0.0461\n",
      "Epoch 98, Loss: 0.0454\n",
      "Epoch 99, Loss: 0.0459\n",
      "Epoch 100, Loss: 0.0462\n",
      "Epoch 101, Loss: 0.0422\n",
      "Epoch 102, Loss: 0.0438\n",
      "Epoch 103, Loss: 0.0426\n",
      "Epoch 104, Loss: 0.0420\n",
      "Epoch 105, Loss: 0.0440\n",
      "Epoch 106, Loss: 0.0437\n",
      "Epoch 107, Loss: 0.0417\n",
      "Epoch 108, Loss: 0.0436\n",
      "Epoch 109, Loss: 0.0426\n",
      "Epoch 110, Loss: 0.0425\n",
      "Epoch 111, Loss: 0.0414\n",
      "Epoch 112, Loss: 0.0407\n",
      "Epoch 113, Loss: 0.0419\n",
      "Epoch 114, Loss: 0.0408\n",
      "Epoch 115, Loss: 0.0414\n",
      "Epoch 116, Loss: 0.0415\n",
      "Epoch 117, Loss: 0.0408\n",
      "Epoch 118, Loss: 0.0415\n",
      "Epoch 119, Loss: 0.0394\n",
      "Epoch 120, Loss: 0.0403\n",
      "Epoch 121, Loss: 0.0394\n",
      "Epoch 122, Loss: 0.0390\n",
      "Epoch 123, Loss: 0.0398\n",
      "Epoch 124, Loss: 0.0381\n",
      "Epoch 125, Loss: 0.0375\n",
      "Epoch 126, Loss: 0.0389\n",
      "Epoch 127, Loss: 0.0368\n",
      "Epoch 128, Loss: 0.0391\n",
      "Epoch 129, Loss: 0.0385\n",
      "Epoch 130, Loss: 0.0365\n",
      "Epoch 131, Loss: 0.0380\n",
      "Epoch 132, Loss: 0.0373\n",
      "Epoch 133, Loss: 0.0371\n",
      "Epoch 134, Loss: 0.0364\n",
      "Epoch 135, Loss: 0.0370\n",
      "Epoch 136, Loss: 0.0351\n",
      "Epoch 137, Loss: 0.0356\n",
      "Epoch 138, Loss: 0.0385\n",
      "Epoch 139, Loss: 0.0356\n",
      "Epoch 140, Loss: 0.0369\n",
      "Epoch 141, Loss: 0.0359\n",
      "Epoch 142, Loss: 0.0352\n",
      "Epoch 143, Loss: 0.0359\n",
      "Epoch 144, Loss: 0.0363\n",
      "Epoch 145, Loss: 0.0349\n",
      "Epoch 146, Loss: 0.0337\n",
      "Epoch 147, Loss: 0.0347\n",
      "Epoch 148, Loss: 0.0355\n",
      "Epoch 149, Loss: 0.0351\n",
      "Epoch 150, Loss: 0.0343\n",
      "Epoch 151, Loss: 0.0342\n",
      "Epoch 152, Loss: 0.0338\n",
      "Epoch 153, Loss: 0.0357\n",
      "Epoch 154, Loss: 0.0328\n",
      "Epoch 155, Loss: 0.0344\n",
      "Epoch 156, Loss: 0.0337\n",
      "Epoch 157, Loss: 0.0327\n",
      "Epoch 158, Loss: 0.0339\n",
      "Epoch 159, Loss: 0.0329\n",
      "Epoch 160, Loss: 0.0337\n",
      "Epoch 161, Loss: 0.0329\n",
      "Epoch 162, Loss: 0.0333\n",
      "Epoch 163, Loss: 0.0325\n",
      "Epoch 164, Loss: 0.0330\n",
      "Epoch 165, Loss: 0.0322\n",
      "Epoch 166, Loss: 0.0326\n",
      "Epoch 167, Loss: 0.0339\n",
      "Epoch 168, Loss: 0.0328\n",
      "Epoch 169, Loss: 0.0323\n",
      "Epoch 170, Loss: 0.0315\n",
      "Epoch 171, Loss: 0.0308\n",
      "Epoch 172, Loss: 0.0315\n",
      "Epoch 173, Loss: 0.0329\n",
      "Epoch 174, Loss: 0.0319\n",
      "Epoch 175, Loss: 0.0328\n",
      "Epoch 176, Loss: 0.0325\n",
      "Epoch 177, Loss: 0.0319\n",
      "Epoch 178, Loss: 0.0308\n",
      "Epoch 179, Loss: 0.0309\n",
      "Epoch 180, Loss: 0.0322\n",
      "Epoch 181, Loss: 0.0325\n",
      "Epoch 182, Loss: 0.0315\n",
      "Epoch 183, Loss: 0.0303\n",
      "Epoch 184, Loss: 0.0299\n",
      "Epoch 185, Loss: 0.0313\n",
      "Epoch 186, Loss: 0.0311\n",
      "Epoch 187, Loss: 0.0310\n",
      "Epoch 188, Loss: 0.0304\n",
      "Epoch 189, Loss: 0.0303\n",
      "Epoch 190, Loss: 0.0304\n",
      "Epoch 191, Loss: 0.0310\n",
      "Epoch 192, Loss: 0.0314\n",
      "Epoch 193, Loss: 0.0306\n",
      "Epoch 194, Loss: 0.0301\n",
      "Epoch 195, Loss: 0.0308\n",
      "Epoch 196, Loss: 0.0311\n",
      "Epoch 197, Loss: 0.0300\n",
      "Epoch 198, Loss: 0.0297\n",
      "Epoch 199, Loss: 0.0304\n",
      "Epoch 200, Loss: 0.0300\n",
      "Epoch 201, Loss: 0.0307\n",
      "Epoch 202, Loss: 0.0292\n",
      "Epoch 203, Loss: 0.0307\n",
      "Epoch 204, Loss: 0.0297\n",
      "Epoch 205, Loss: 0.0271\n",
      "Epoch 206, Loss: 0.0283\n",
      "Epoch 207, Loss: 0.0285\n",
      "Epoch 208, Loss: 0.0293\n",
      "Epoch 209, Loss: 0.0290\n",
      "Epoch 210, Loss: 0.0292\n",
      "Epoch 211, Loss: 0.0286\n",
      "Epoch 212, Loss: 0.0295\n",
      "Epoch 213, Loss: 0.0296\n",
      "Epoch 214, Loss: 0.0274\n",
      "Epoch 215, Loss: 0.0306\n",
      "Epoch 216, Loss: 0.0310\n",
      "Epoch 217, Loss: 0.0273\n",
      "Epoch 218, Loss: 0.0280\n",
      "Epoch 219, Loss: 0.0271\n",
      "Epoch 220, Loss: 0.0289\n",
      "Epoch 221, Loss: 0.0270\n",
      "Epoch 222, Loss: 0.0281\n",
      "Epoch 223, Loss: 0.0284\n",
      "Epoch 224, Loss: 0.0280\n",
      "Epoch 225, Loss: 0.0292\n",
      "Epoch 226, Loss: 0.0276\n",
      "Epoch 227, Loss: 0.0298\n",
      "Epoch 228, Loss: 0.0280\n",
      "Epoch 229, Loss: 0.0272\n",
      "Epoch 230, Loss: 0.0287\n",
      "Epoch 231, Loss: 0.0270\n",
      "Epoch 232, Loss: 0.0304\n",
      "Epoch 233, Loss: 0.0282\n",
      "Epoch 234, Loss: 0.0281\n",
      "Epoch 235, Loss: 0.0267\n",
      "Epoch 236, Loss: 0.0269\n",
      "Epoch 237, Loss: 0.0293\n",
      "Epoch 238, Loss: 0.0287\n",
      "Epoch 239, Loss: 0.0283\n",
      "Epoch 240, Loss: 0.0265\n",
      "Epoch 241, Loss: 0.0282\n",
      "Epoch 242, Loss: 0.0273\n",
      "Epoch 243, Loss: 0.0280\n",
      "Epoch 244, Loss: 0.0256\n",
      "Epoch 245, Loss: 0.0274\n",
      "Epoch 246, Loss: 0.0270\n",
      "Epoch 247, Loss: 0.0265\n",
      "Epoch 248, Loss: 0.0289\n",
      "Epoch 249, Loss: 0.0270\n",
      "Epoch 250, Loss: 0.0266\n",
      "Epoch 251, Loss: 0.0276\n",
      "Epoch 252, Loss: 0.0278\n",
      "Epoch 253, Loss: 0.0284\n",
      "Epoch 254, Loss: 0.0290\n",
      "Epoch 255, Loss: 0.0276\n",
      "Epoch 256, Loss: 0.0281\n",
      "Epoch 257, Loss: 0.0275\n",
      "Epoch 258, Loss: 0.0263\n",
      "Epoch 259, Loss: 0.0253\n",
      "Epoch 260, Loss: 0.0285\n",
      "Epoch 261, Loss: 0.0276\n",
      "Epoch 262, Loss: 0.0277\n",
      "Epoch 263, Loss: 0.0271\n",
      "Epoch 264, Loss: 0.0267\n",
      "Epoch 265, Loss: 0.0252\n",
      "Epoch 266, Loss: 0.0272\n",
      "Epoch 267, Loss: 0.0258\n",
      "Epoch 268, Loss: 0.0249\n",
      "Epoch 269, Loss: 0.0267\n",
      "Epoch 270, Loss: 0.0273\n",
      "Epoch 271, Loss: 0.0260\n",
      "Epoch 272, Loss: 0.0267\n",
      "Epoch 273, Loss: 0.0254\n",
      "Epoch 274, Loss: 0.0269\n",
      "Epoch 275, Loss: 0.0256\n",
      "Epoch 276, Loss: 0.0258\n",
      "Epoch 277, Loss: 0.0249\n",
      "Epoch 278, Loss: 0.0247\n",
      "Epoch 279, Loss: 0.0259\n",
      "Epoch 280, Loss: 0.0256\n",
      "Epoch 281, Loss: 0.0252\n",
      "Epoch 282, Loss: 0.0244\n",
      "Epoch 283, Loss: 0.0268\n",
      "Epoch 284, Loss: 0.0261\n",
      "Epoch 285, Loss: 0.0252\n",
      "Epoch 286, Loss: 0.0260\n",
      "Epoch 287, Loss: 0.0242\n",
      "Epoch 288, Loss: 0.0251\n",
      "Epoch 289, Loss: 0.0256\n",
      "Epoch 290, Loss: 0.0252\n",
      "Epoch 291, Loss: 0.0247\n",
      "Epoch 292, Loss: 0.0241\n",
      "Epoch 293, Loss: 0.0253\n",
      "Epoch 294, Loss: 0.0252\n",
      "Epoch 295, Loss: 0.0262\n",
      "Epoch 296, Loss: 0.0262\n",
      "Epoch 297, Loss: 0.0270\n",
      "Epoch 298, Loss: 0.0254\n",
      "Epoch 299, Loss: 0.0258\n",
      "Epoch 300, Loss: 0.0254\n",
      "Epoch 301, Loss: 0.0260\n",
      "Epoch 302, Loss: 0.0259\n",
      "Epoch 303, Loss: 0.0255\n",
      "Epoch 304, Loss: 0.0250\n",
      "Epoch 305, Loss: 0.0258\n",
      "Epoch 306, Loss: 0.0228\n",
      "Epoch 307, Loss: 0.0249\n",
      "Epoch 308, Loss: 0.0242\n",
      "Epoch 309, Loss: 0.0257\n",
      "Epoch 310, Loss: 0.0261\n",
      "Epoch 311, Loss: 0.0250\n",
      "Epoch 312, Loss: 0.0243\n",
      "Epoch 313, Loss: 0.0261\n",
      "Epoch 314, Loss: 0.0263\n",
      "Epoch 315, Loss: 0.0235\n",
      "Epoch 316, Loss: 0.0250\n",
      "Epoch 317, Loss: 0.0235\n",
      "Epoch 318, Loss: 0.0240\n",
      "Epoch 319, Loss: 0.0246\n",
      "Epoch 320, Loss: 0.0234\n",
      "Epoch 321, Loss: 0.0255\n",
      "Epoch 322, Loss: 0.0250\n",
      "Epoch 323, Loss: 0.0255\n",
      "Epoch 324, Loss: 0.0247\n",
      "Epoch 325, Loss: 0.0239\n",
      "Epoch 326, Loss: 0.0250\n",
      "Epoch 327, Loss: 0.0236\n",
      "Epoch 328, Loss: 0.0242\n",
      "Epoch 329, Loss: 0.0245\n",
      "Epoch 330, Loss: 0.0236\n",
      "Epoch 331, Loss: 0.0254\n",
      "Epoch 332, Loss: 0.0236\n",
      "Epoch 333, Loss: 0.0244\n",
      "Epoch 334, Loss: 0.0238\n",
      "Epoch 335, Loss: 0.0251\n",
      "Epoch 336, Loss: 0.0251\n",
      "Epoch 337, Loss: 0.0233\n",
      "Epoch 338, Loss: 0.0248\n",
      "Epoch 339, Loss: 0.0235\n",
      "Epoch 340, Loss: 0.0243\n",
      "Epoch 341, Loss: 0.0242\n",
      "Epoch 342, Loss: 0.0238\n",
      "Epoch 343, Loss: 0.0257\n",
      "Epoch 344, Loss: 0.0244\n",
      "Epoch 345, Loss: 0.0250\n",
      "Epoch 346, Loss: 0.0235\n",
      "Epoch 347, Loss: 0.0246\n",
      "Epoch 348, Loss: 0.0244\n",
      "Epoch 349, Loss: 0.0230\n",
      "Epoch 350, Loss: 0.0267\n",
      "Epoch 351, Loss: 0.0229\n",
      "Epoch 352, Loss: 0.0246\n",
      "Epoch 353, Loss: 0.0235\n",
      "Epoch 354, Loss: 0.0245\n",
      "Epoch 355, Loss: 0.0244\n",
      "Epoch 356, Loss: 0.0243\n",
      "Epoch 357, Loss: 0.0246\n",
      "Epoch 358, Loss: 0.0242\n",
      "Epoch 359, Loss: 0.0232\n",
      "Epoch 360, Loss: 0.0255\n",
      "Epoch 361, Loss: 0.0247\n",
      "Epoch 362, Loss: 0.0229\n",
      "Epoch 363, Loss: 0.0246\n",
      "Epoch 364, Loss: 0.0244\n",
      "Epoch 365, Loss: 0.0248\n",
      "Epoch 366, Loss: 0.0252\n",
      "Epoch 367, Loss: 0.0236\n",
      "Epoch 368, Loss: 0.0235\n",
      "Epoch 369, Loss: 0.0235\n",
      "Epoch 370, Loss: 0.0230\n",
      "Epoch 371, Loss: 0.0217\n",
      "Epoch 372, Loss: 0.0240\n",
      "Epoch 373, Loss: 0.0247\n",
      "Epoch 374, Loss: 0.0238\n",
      "Epoch 375, Loss: 0.0244\n",
      "Epoch 376, Loss: 0.0232\n",
      "Epoch 377, Loss: 0.0229\n",
      "Epoch 378, Loss: 0.0235\n",
      "Epoch 379, Loss: 0.0225\n",
      "Epoch 380, Loss: 0.0238\n",
      "Epoch 381, Loss: 0.0240\n",
      "Epoch 382, Loss: 0.0234\n",
      "Epoch 383, Loss: 0.0238\n",
      "Epoch 384, Loss: 0.0242\n",
      "Epoch 385, Loss: 0.0234\n",
      "Epoch 386, Loss: 0.0221\n",
      "Epoch 387, Loss: 0.0225\n",
      "Epoch 388, Loss: 0.0224\n",
      "Epoch 389, Loss: 0.0238\n",
      "Epoch 390, Loss: 0.0228\n",
      "Epoch 391, Loss: 0.0246\n",
      "Epoch 392, Loss: 0.0243\n",
      "Epoch 393, Loss: 0.0241\n",
      "Epoch 394, Loss: 0.0217\n",
      "Epoch 395, Loss: 0.0241\n",
      "Epoch 396, Loss: 0.0229\n",
      "Epoch 397, Loss: 0.0247\n",
      "Epoch 398, Loss: 0.0240\n",
      "Epoch 399, Loss: 0.0245\n",
      "Epoch 400, Loss: 0.0229\n",
      "Epoch 401, Loss: 0.0251\n",
      "Epoch 402, Loss: 0.0244\n",
      "Epoch 403, Loss: 0.0225\n",
      "Epoch 404, Loss: 0.0228\n",
      "Epoch 405, Loss: 0.0224\n",
      "Epoch 406, Loss: 0.0224\n",
      "Epoch 407, Loss: 0.0233\n",
      "Epoch 408, Loss: 0.0232\n",
      "Epoch 409, Loss: 0.0241\n",
      "Epoch 410, Loss: 0.0230\n",
      "Epoch 411, Loss: 0.0247\n",
      "Epoch 412, Loss: 0.0242\n",
      "Epoch 413, Loss: 0.0230\n",
      "Epoch 414, Loss: 0.0230\n",
      "Epoch 415, Loss: 0.0237\n",
      "Epoch 416, Loss: 0.0229\n",
      "Epoch 417, Loss: 0.0246\n",
      "Epoch 418, Loss: 0.0224\n",
      "Epoch 419, Loss: 0.0234\n",
      "Epoch 420, Loss: 0.0248\n",
      "Epoch 421, Loss: 0.0233\n",
      "Epoch 422, Loss: 0.0230\n",
      "Epoch 423, Loss: 0.0238\n",
      "Epoch 424, Loss: 0.0242\n",
      "Epoch 425, Loss: 0.0214\n",
      "Epoch 426, Loss: 0.0212\n",
      "Epoch 427, Loss: 0.0225\n",
      "Epoch 428, Loss: 0.0225\n",
      "Epoch 429, Loss: 0.0221\n",
      "Epoch 430, Loss: 0.0227\n",
      "Epoch 431, Loss: 0.0226\n",
      "Epoch 432, Loss: 0.0232\n",
      "Epoch 433, Loss: 0.0211\n",
      "Epoch 434, Loss: 0.0236\n",
      "Epoch 435, Loss: 0.0223\n",
      "Epoch 436, Loss: 0.0243\n",
      "Epoch 437, Loss: 0.0221\n",
      "Epoch 438, Loss: 0.0244\n",
      "Epoch 439, Loss: 0.0230\n",
      "Epoch 440, Loss: 0.0224\n",
      "Epoch 441, Loss: 0.0231\n",
      "Epoch 442, Loss: 0.0232\n",
      "Epoch 443, Loss: 0.0223\n",
      "Epoch 444, Loss: 0.0217\n",
      "Epoch 445, Loss: 0.0203\n",
      "Epoch 446, Loss: 0.0216\n",
      "Epoch 447, Loss: 0.0230\n",
      "Epoch 448, Loss: 0.0239\n",
      "Epoch 449, Loss: 0.0218\n",
      "Epoch 450, Loss: 0.0227\n",
      "Epoch 451, Loss: 0.0220\n",
      "Epoch 452, Loss: 0.0229\n",
      "Epoch 453, Loss: 0.0219\n",
      "Epoch 454, Loss: 0.0225\n",
      "Epoch 455, Loss: 0.0231\n",
      "Epoch 456, Loss: 0.0238\n",
      "Epoch 457, Loss: 0.0228\n",
      "Epoch 458, Loss: 0.0258\n",
      "Epoch 459, Loss: 0.0242\n",
      "Epoch 460, Loss: 0.0239\n",
      "Epoch 461, Loss: 0.0225\n",
      "Epoch 462, Loss: 0.0237\n",
      "Epoch 463, Loss: 0.0233\n",
      "Epoch 464, Loss: 0.0228\n",
      "Epoch 465, Loss: 0.0244\n",
      "Epoch 466, Loss: 0.0227\n",
      "Epoch 467, Loss: 0.0226\n",
      "Epoch 468, Loss: 0.0220\n",
      "Epoch 469, Loss: 0.0227\n",
      "Epoch 470, Loss: 0.0225\n",
      "Epoch 471, Loss: 0.0225\n",
      "Epoch 472, Loss: 0.0221\n",
      "Epoch 473, Loss: 0.0215\n",
      "Epoch 474, Loss: 0.0225\n",
      "Epoch 475, Loss: 0.0231\n",
      "Epoch 476, Loss: 0.0228\n",
      "Epoch 477, Loss: 0.0256\n",
      "Epoch 478, Loss: 0.0228\n",
      "Epoch 479, Loss: 0.0215\n",
      "Epoch 480, Loss: 0.0236\n",
      "Epoch 481, Loss: 0.0209\n",
      "Epoch 482, Loss: 0.0216\n",
      "Epoch 483, Loss: 0.0208\n",
      "Epoch 484, Loss: 0.0238\n",
      "Epoch 485, Loss: 0.0228\n",
      "Epoch 486, Loss: 0.0223\n",
      "Epoch 487, Loss: 0.0213\n",
      "Epoch 488, Loss: 0.0226\n",
      "Epoch 489, Loss: 0.0228\n",
      "Epoch 490, Loss: 0.0238\n",
      "Epoch 491, Loss: 0.0233\n",
      "Epoch 492, Loss: 0.0222\n",
      "Epoch 493, Loss: 0.0241\n",
      "Epoch 494, Loss: 0.0219\n",
      "Epoch 495, Loss: 0.0233\n",
      "Epoch 496, Loss: 0.0239\n",
      "Epoch 497, Loss: 0.0224\n",
      "Epoch 498, Loss: 0.0228\n",
      "Epoch 499, Loss: 0.0230\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(500):\n",
    "\n",
    "    users, pos_items, neg_items = generate_train_data(user_pos_items, num_items)\n",
    "\n",
    "    users = users.to(device)\n",
    "    pos_items = pos_items.to(device)\n",
    "    neg_items = neg_items.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    num_batches = len(users) // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        batch_users = users[i*batch_size:(i+1)*batch_size]\n",
    "        batch_pos = pos_items[i*batch_size:(i+1)*batch_size]\n",
    "        batch_neg = neg_items[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        pos_scores = model(batch_users, batch_pos)\n",
    "        neg_scores = model(batch_users, batch_neg)\n",
    "\n",
    "        loss = bpr_loss(pos_scores, neg_scores)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss /= num_batches\n",
    "    loss_list.append(epoch_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b37edd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BPR Loss\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "658241e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(model, train_dict, test_data, num_items, k=10):\n",
    "    model.eval()\n",
    "    hit = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, row in test_data.iterrows():\n",
    "            user = int(row[\"user\"])\n",
    "            true_item = int(row[\"item\"])\n",
    "\n",
    "            user_tensor = torch.LongTensor([user]).to(device)\n",
    "\n",
    "            all_items = torch.arange(num_items).to(device)\n",
    "\n",
    "            scores = model(\n",
    "                user_tensor.repeat(num_items),\n",
    "                all_items\n",
    "            )\n",
    "\n",
    "            # 去掉训练集中看过的物品\n",
    "            train_items = train_dict[user]\n",
    "            scores[list(train_items)] = -1e9\n",
    "\n",
    "            topk = torch.topk(scores, k).indices.cpu().numpy()\n",
    "\n",
    "            if true_item in topk:\n",
    "                hit += 1\n",
    "\n",
    "    return hit / len(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db8035d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.0975609756097561\n"
     ]
    }
   ],
   "source": [
    "recall = recall_at_k(model, user_pos_items, test_data, num_items, k=10)\n",
    "print(\"Recall@10:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f74132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
