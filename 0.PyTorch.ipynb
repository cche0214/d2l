{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca8d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9324d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff91decb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b261b8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c6db069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4585, 0.5966],\n",
       "        [0.3531, 0.7411]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad2e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个包含两个整数的元组，生成一个二维张量\n",
    "# 一个shape的本质是每一层嵌套列表的长度\n",
    "shape = (2, 3, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a854f5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1259, 0.1687, 0.9357],\n",
       "        [0.1229, 0.3297, 0.9095]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor = torch.rand(shape)\n",
    "rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4827d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_tensor = torch.ones(shape)\n",
    "ones_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cb6da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(shape)\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4dfe53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0510, 0.3700, 0.2253, 0.4510],\n",
       "        [0.5616, 0.6691, 0.6466, 0.2658],\n",
       "        [0.9096, 0.4435, 0.0712, 0.6467]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "645c6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor:torch.Size([3, 4])\n",
      "DataType of tensor:torch.float32\n",
      "Device tensor is stored on:cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor:{tensor.shape}\")\n",
    "print(f\"DataType of tensor:{tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on:{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c533d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9463e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "tensor = tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91970be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor:torch.Size([3, 4])\n",
      "DataType of tensor:torch.float32\n",
      "Device tensor is stored on:cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor:{tensor.shape}\")\n",
    "print(f\"DataType of tensor:{tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on:{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc9eb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1713, 0.8082, 0.4766, 0.7439],\n",
       "        [0.9173, 0.7774, 0.1338, 0.8414],\n",
       "        [0.9684, 0.4996, 0.4894, 0.3578],\n",
       "        [0.3141, 0.0701, 0.8453, 0.5963]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eac6e720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:tensor([0.1713, 0.8082, 0.4766, 0.7439]), First row shape:torch.Size([4])\n",
      "First column:tensor([0.1713, 0.9173, 0.9684, 0.3141])\n",
      "Last column: tensor([0.7439, 0.8414, 0.3578, 0.5963])\n",
      "Last column:tensor([0.7439, 0.8414, 0.3578, 0.5963])\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row:{tensor[0]}, First row shape:{tensor[0].shape}\")\n",
    "print(f\"First column:{tensor[:, 0]}\")\n",
    "# ...表示对前面的所有维度进行:操作，因为这里是二维的，所以等价\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "print(f\"Last column:{tensor[:, -1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270eed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# PyTorch 张量索引与 shape 理解笔记\n",
    "# ================================\n",
    "\n",
    "# 一、什么是 shape？\n",
    "# shape 表示：每一层嵌套结构的长度\n",
    "# shape 有几项，就表示有几层嵌套\n",
    "#\n",
    "# 例如：\n",
    "# (4,)          → 一维数组，长度 4\n",
    "# (4,4)         → 二维数组，4 行 4 列\n",
    "# (2,3,4)       → 三维数组，2 个 3x4 矩阵\n",
    "# (5,10,28,28)  → 四维数组\n",
    "\n",
    "# 可以记住一句话：\n",
    "# shape 有几项 = 嵌套几层\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 二、高维张量怎么想象？\n",
    "# ================================\n",
    "\n",
    "# 例如：\n",
    "# x.shape = (5, 10, 28, 28)\n",
    "\n",
    "# 可以理解为：\n",
    "# [样本, 通道, 行, 列]\n",
    "\n",
    "# 想象成：\n",
    "# 5 个样本\n",
    "# 每个样本 10 个通道\n",
    "# 每个通道是 28x28 的矩阵\n",
    "\n",
    "# 或者类比为：\n",
    "# 5 本书\n",
    "# 每本书 10 页\n",
    "# 每页 28 行 28 列\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 三、索引的核心规则\n",
    "# ================================\n",
    "\n",
    "# 规则 1：\n",
    "# 使用整数索引（比如 0、-1）\n",
    "# → 该维度会被压缩（消失）\n",
    "\n",
    "# 规则 2：\n",
    "# 使用切片（比如 0:1、0:2）\n",
    "# → 该维度保留（只是长度改变）\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 四、二维例子理解整数 vs 切片\n",
    "# ================================\n",
    "\n",
    "# A.shape = (4,4)\n",
    "\n",
    "# A[:, 0]\n",
    "# → 取所有行，第 0 列\n",
    "# → 结果是一维\n",
    "# → shape = (4,)\n",
    "\n",
    "# 结构：\n",
    "# [a, e, i, m]\n",
    "\n",
    "# A[:, 0:1]\n",
    "# → 取所有行，第 0 列（切片）\n",
    "# → 结果是二维\n",
    "# → shape = (4,1)\n",
    "\n",
    "# 结构：\n",
    "# [\n",
    "#  [a],\n",
    "#  [e],\n",
    "#  [i],\n",
    "#  [m]\n",
    "# ]\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 五、四维张量索引推理\n",
    "# ================================\n",
    "\n",
    "# x.shape = (5, 10, 28, 28)\n",
    "# 维度含义：\n",
    "# [样本, 通道, 行, 列]\n",
    "\n",
    "\n",
    "# 情况 1：\n",
    "# x[0]\n",
    "# 第一维整数索引 → 压缩\n",
    "# 结果：\n",
    "# (10, 28, 28)\n",
    "\n",
    "\n",
    "# 情况 2：\n",
    "# x[:, 0]\n",
    "# 第二维整数索引 → 压缩\n",
    "# 结果：\n",
    "# (5, 28, 28)\n",
    "\n",
    "\n",
    "# 情况 3：\n",
    "# x[:, 0, :, 0]\n",
    "# 第二维整数索引 → 压缩\n",
    "# 第四维整数索引 → 压缩\n",
    "# 结果：\n",
    "# (5, 28)\n",
    "\n",
    "\n",
    "# 情况 4：\n",
    "# x[:, 0:1, :, 0]\n",
    "# 第二维是切片 → 保留\n",
    "# 第四维是整数 → 压缩\n",
    "# 结果：\n",
    "# (5, 1, 28)\n",
    "\n",
    "\n",
    "# 情况 5：\n",
    "# x[:, 0:2, :, 0]\n",
    "# 第二维是切片 → 保留（长度变 2）\n",
    "# 第四维整数索引 → 压缩\n",
    "# 结果：\n",
    "# (5, 2, 28)\n",
    "\n",
    "\n",
    "# 情况 6：\n",
    "# x[:, 0:2, :, 0:1]\n",
    "# 第二维切片 → 保留（长度 2）\n",
    "# 第四维切片 → 保留（长度 1）\n",
    "# 结果：\n",
    "# (5, 2, 28, 1)\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 六、终极记忆口诀\n",
    "# ================================\n",
    "\n",
    "# 整数索引 → 拿一个元素 → 那一维消失\n",
    "# 切片索引 → 拿一段 → 那一维还在\n",
    "\n",
    "# 0      → 取一个 → 压缩维度\n",
    "# 0:1    → 取一个范围 → 保留维度\n",
    "# 0:2    → 取两个 → 保留维度（长度变2）\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 七、为什么这很重要？\n",
    "# ================================\n",
    "\n",
    "# 深度学习中常见输入格式：\n",
    "# (batch, channel, height, width)\n",
    "\n",
    "# 有时即使某个维度长度是 1\n",
    "# 也必须保留该维度\n",
    "# 否则模型会报错\n",
    "\n",
    "# 所以：\n",
    "# 保留维度 vs 压缩维度\n",
    "# 在实际网络中非常关键\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 八、总结\n",
    "# ================================\n",
    "\n",
    "# 1. shape 表示嵌套层级结构\n",
    "# 2. 整数索引会削维\n",
    "# 3. 切片不会削维\n",
    "# 4. 推理时逐维分析\n",
    "# 5. 维度变化=从左到右依次判断是否压缩\n",
    "\n",
    "# 掌握以上规则后：\n",
    "# 任何高维张量索引都可以机械推出来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103f78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ac8b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=-1)\n",
    "print(t1)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb06b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# PyTorch 中 dim 的完整理解笔记\n",
    "# ==========================================\n",
    "\n",
    "# 一、dim 的本质是什么？\n",
    "# dim 表示：沿着哪一个维度进行操作\n",
    "# 换句话说：\n",
    "# dim 指定“哪个维度的长度会发生变化”\n",
    "\n",
    "# 维度编号规则：\n",
    "# 从左到右编号，从 0 开始\n",
    "\n",
    "# 例如：\n",
    "# shape = (5, 10, 28, 28)\n",
    "# dim=0 → 5   （样本维）\n",
    "# dim=1 → 10  （通道维）\n",
    "# dim=2 → 28  （行）\n",
    "# dim=3 → 28  （列）\n",
    "\n",
    "# 负数 dim 表示从右往左数：\n",
    "# dim=-1 → 最后一维\n",
    "# dim=-2 → 倒数第二维\n",
    "# dim=-3 → 倒数第三维\n",
    "# dim=-4 → 倒数第四维\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 二、二维情况下的 dim 理解\n",
    "# ==========================================\n",
    "\n",
    "# A.shape = (4,4)\n",
    "\n",
    "# dim=0 → 行方向（向下拼接）\n",
    "# dim=1 → 列方向（向右拼接）\n",
    "\n",
    "# 举例：\n",
    "# torch.cat([A, A], dim=0)\n",
    "# → 纵向拼接\n",
    "# → shape 变成 (8,4)\n",
    "\n",
    "# torch.cat([A, A], dim=1)\n",
    "# → 横向拼接\n",
    "# → shape 变成 (4,8)\n",
    "\n",
    "# 记忆方法：\n",
    "# dim=0 → 行数增加\n",
    "# dim=1 → 列数增加\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 三、三维情况下的 dim\n",
    "# ==========================================\n",
    "\n",
    "# x.shape = (2, 3, 4)\n",
    "# 可以理解为：\n",
    "# (块, 行, 列)\n",
    "\n",
    "# dim=0 → 块数增加\n",
    "# dim=1 → 行数增加\n",
    "# dim=2 → 列数增加\n",
    "\n",
    "# 例如：\n",
    "# torch.cat([x, x], dim=1)\n",
    "# shape 从 (2,3,4)\n",
    "# 变成 (2,6,4)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 四、四维图像例子（最常见）\n",
    "# ==========================================\n",
    "\n",
    "# x.shape = (5, 10, 28, 28)\n",
    "# 语义理解为：\n",
    "# (batch, channel, height, width)\n",
    "\n",
    "# dim=0 → 增加样本数量\n",
    "# dim=1 → 增加通道数量\n",
    "# dim=2 → 增加高度（纵向变大）\n",
    "# dim=3 → 增加宽度（横向变大）\n",
    "# dim=-1 等价于 dim=3\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 五、具体例子总结\n",
    "# ==========================================\n",
    "\n",
    "# 原始：\n",
    "# x.shape = (5, 10, 28, 28)\n",
    "\n",
    "# 1）torch.cat([x, x], dim=0)\n",
    "# → (10, 10, 28, 28)\n",
    "# 含义：样本数量翻倍\n",
    "\n",
    "# 2）torch.cat([x, x], dim=1)\n",
    "# → (5, 20, 28, 28)\n",
    "# 含义：每个样本通道翻倍\n",
    "\n",
    "# 3）torch.cat([x, x], dim=2)\n",
    "# → (5, 10, 56, 28)\n",
    "# 含义：高度翻倍（纵向拼接）\n",
    "\n",
    "# 4）torch.cat([x, x], dim=3)\n",
    "# → (5, 10, 28, 56)\n",
    "# 含义：宽度翻倍（横向拼接）\n",
    "\n",
    "# 5）torch.cat([x, x], dim=-1)\n",
    "# → 等价于 dim=3\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 六、最核心的理解公式\n",
    "# ==========================================\n",
    "\n",
    "# 对于：\n",
    "# shape = (d0, d1, d2, ..., dn)\n",
    "\n",
    "# 如果：\n",
    "# torch.cat(..., dim=k)\n",
    "\n",
    "# 那么：\n",
    "# 只有 dk 会变大\n",
    "# 其他维度必须保持一致\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 七、dim 的思维模型\n",
    "# ==========================================\n",
    "\n",
    "# 把张量想成多层嵌套盒子：\n",
    "# dim 指定你在哪一层盒子上做“扩展”\n",
    "\n",
    "# 举例：\n",
    "# (5, 10, 28, 28)\n",
    "# 就是：\n",
    "# 5 个大盒子\n",
    "# 每个大盒子 10 个中盒子\n",
    "# 每个中盒子 28 行\n",
    "# 每行 28 个元素\n",
    "\n",
    "# dim=1 就是在“中盒子数量”那一层增加\n",
    "# dim=2 就是在“行数量”那一层增加\n",
    "# dim=3 就是在“列数量”那一层增加\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 八、终极记忆方式\n",
    "# ==========================================\n",
    "\n",
    "# dim = 哪个维度的长度会变大\n",
    "# dim = 从左往右编号\n",
    "# dim = 负数时从右往左数\n",
    "\n",
    "# 只要盯住 shape：\n",
    "# 看第几个数字变大\n",
    "# 就能理解 dim 的意义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd66d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0becd212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d3c9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y1 = tensor @ tensor.T\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c525d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "y2 = tensor.matmul(tensor.T)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0808c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @是矩阵乘法，等价于torch.matmul(A, B)，等价A.matmul(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ed42b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2343, 0.3072, 0.7460, 0.0704],\n",
      "        [0.9397, 0.1483, 0.2693, 0.8653],\n",
      "        [0.1258, 0.6016, 0.8309, 0.2629],\n",
      "        [0.1074, 0.8717, 0.0952, 0.2974]])\n"
     ]
    }
   ],
   "source": [
    "y3 = torch.rand_like(y1)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffa0da37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89fe3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# out=y3的意思是把结果写进y3里面\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c35ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 这个是逐元素乘法，不是矩阵乘法\n",
    "z1 = tensor * tensor\n",
    "print(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd496412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z2 = tensor.mul(tensor)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "febe7438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1481, 0.3081, 0.0723, 0.8016],\n",
      "        [0.6926, 0.2996, 0.8987, 0.3498],\n",
      "        [0.7652, 0.7044, 0.8002, 0.0435],\n",
      "        [0.2186, 0.2178, 0.3723, 0.0752]])\n"
     ]
    }
   ],
   "source": [
    "z3 = torch.rand_like(tensor)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb093e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40c4c4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf07004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3c4c2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23d11176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "# 函数名字中带下划线的就是原地修改，但是不推荐用\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "260a1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([1., 1., 1., 1., 1.])\n",
      "n:[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t:{t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f5d13d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([2., 2., 2., 2., 2.])\n",
      "n:[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# 共享底层内存，一个变化另一个也会变化\n",
    "t.add_(1)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1376f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1adba54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4809137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62135355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(n, 1, out=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e9434a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6071d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Fashion-MNIST 数据集理解笔记\n",
    "# ==========================================\n",
    "\n",
    "# 一、数据集基本信息\n",
    "# ------------------------------------------\n",
    "# Fashion-MNIST 是一个图像分类数据集\n",
    "# 训练集：60000 张图片\n",
    "# 测试集：10000 张图片\n",
    "# 总类别数：10 类（不同种类的服装）\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 二、单张图片的结构\n",
    "# ==========================================\n",
    "\n",
    "# 每张图片大小：\n",
    "# 28 × 28 像素\n",
    "\n",
    "# 是灰度图（grayscale）\n",
    "# 灰度图只有 1 个通道\n",
    "\n",
    "# 在 PyTorch 中通常表示为：\n",
    "# (channel, height, width)\n",
    "\n",
    "# 所以单张图片的 shape 是：\n",
    "# (1, 28, 28)\n",
    "\n",
    "# 解释：\n",
    "# channel = 1（只有亮度信息）\n",
    "# height  = 28\n",
    "# width   = 28\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 三、什么是“通道”？\n",
    "# ==========================================\n",
    "\n",
    "# 通道表示“不同种类的像素信息层”\n",
    "\n",
    "# 灰度图：\n",
    "# 1 个通道（只有亮度）\n",
    "\n",
    "# 彩色图：\n",
    "# 3 个通道（R、G、B）\n",
    "\n",
    "# 每个通道本质上是一个二维矩阵\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 四、像素是什么？\n",
    "# ==========================================\n",
    "\n",
    "# 像素是一个数值\n",
    "# 表示该位置的亮度大小\n",
    "\n",
    "# 原始范围通常：\n",
    "# 0   → 黑色\n",
    "# 255 → 白色\n",
    "\n",
    "# 在深度学习中通常会归一化到：\n",
    "# 0~1 之间\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 五、整个训练集长什么样？\n",
    "# ==========================================\n",
    "\n",
    "# 如果把 60000 张图片堆叠在一起：\n",
    "\n",
    "# images.shape = (60000, 1, 28, 28)\n",
    "\n",
    "# 解释：\n",
    "# 60000 个样本\n",
    "# 每个样本 1 个通道\n",
    "# 每个通道 28×28\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 六、标签结构\n",
    "# ==========================================\n",
    "\n",
    "# 每张图片对应一个类别编号\n",
    "\n",
    "# 标签 shape：\n",
    "# labels.shape = (60000,)\n",
    "\n",
    "# 每个标签是一个整数：\n",
    "# 0~9\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 七、数据的一条样本结构\n",
    "# ==========================================\n",
    "\n",
    "# 第 i 个样本：\n",
    "\n",
    "# image = images[i]   # shape = (1, 28, 28)\n",
    "# label = labels[i]   # 一个整数\n",
    "\n",
    "# 含义：\n",
    "# image 是一张 28×28 的灰度图\n",
    "# label 表示图片属于哪个类别\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 八、批量数据（DataLoader）\n",
    "# ==========================================\n",
    "\n",
    "# 如果 batch_size = 64\n",
    "\n",
    "# 一个 batch 的图像 shape：\n",
    "# (64, 1, 28, 28)\n",
    "\n",
    "# 标签 shape：\n",
    "# (64,)\n",
    "\n",
    "# 含义：\n",
    "# 一次送入网络 64 张图片\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 九、本质理解\n",
    "# ==========================================\n",
    "\n",
    "# Fashion-MNIST 本质是：\n",
    "\n",
    "# 一个四维张量（图片数据）\n",
    "# +\n",
    "# 一个一维张量（标签）\n",
    "\n",
    "# 所谓“图像数据集”\n",
    "# 本质就是：\n",
    "# 多维数组 + 分类标签\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 十、终极理解\n",
    "# ==========================================\n",
    "\n",
    "# 真实世界图像\n",
    "#     ↓\n",
    "# 像素数值\n",
    "#     ↓\n",
    "# 28×28 数字矩阵\n",
    "#     ↓\n",
    "# (1,28,28) 张量\n",
    "#     ↓\n",
    "# (60000,1,28,28) 数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2194b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()    # 把图片转换成张量\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df27de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(training_data)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07d988c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
      "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
      "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
      "          0.0157, 0.0000, 0.0000, 0.0118],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
      "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0471, 0.0392, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
      "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
      "          0.3020, 0.5098, 0.2824, 0.0588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
      "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
      "          0.5529, 0.3451, 0.6745, 0.2588],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
      "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
      "          0.4824, 0.7686, 0.8980, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
      "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
      "          0.8745, 0.9608, 0.6784, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
      "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
      "          0.8627, 0.9529, 0.7922, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
      "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
      "          0.8863, 0.7725, 0.8196, 0.2039],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
      "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
      "          0.9608, 0.4667, 0.6549, 0.2196],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
      "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
      "          0.8510, 0.8196, 0.3608, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
      "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
      "          0.8549, 1.0000, 0.3020, 0.0000],\n",
      "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
      "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
      "          0.8784, 0.9569, 0.6235, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
      "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
      "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
      "          0.9137, 0.9333, 0.8431, 0.0000],\n",
      "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
      "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
      "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
      "          0.8627, 0.9098, 0.9647, 0.0000],\n",
      "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
      "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
      "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
      "          0.8706, 0.8941, 0.8824, 0.0000],\n",
      "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
      "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
      "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
      "          0.8745, 0.8784, 0.8980, 0.1137],\n",
      "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
      "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
      "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
      "          0.8627, 0.8667, 0.9020, 0.2627],\n",
      "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
      "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
      "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
      "          0.7098, 0.8039, 0.8078, 0.4510],\n",
      "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
      "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
      "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
      "          0.6549, 0.6941, 0.8235, 0.3608],\n",
      "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
      "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
      "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
      "          0.7529, 0.8471, 0.6667, 0.0000],\n",
      "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
      "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
      "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
      "          0.3882, 0.2275, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
      "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 9)\n",
      "2\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(training_data[0])\n",
    "print(len(training_data[0]))\n",
    "print(type(training_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9660287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 1是灰度图的单通道，每个通道就是一个28*28的灰度矩阵，元素表示亮度\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78735af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练数据的样本\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d11a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKQCAYAAAABnneSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbcFJREFUeJzt3Xl0VfX1//8dIGQOZIBACBAGGWRQQWVSQRGcUKrihAMORaq/qrXYj9pWxfq1WqqlLtuqrQpWq0VbBUWLWEWtCogVGQRFBaLMEAiEJIRAzu8PF6mR9+st9xog8H4+1upaZZ+77zn35px7tjfZ+50QRVFkAAAAOOQ1ONAHAAAAgP2Dwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAASCwm8vzZkzx84++2xr06aNJSUlWV5envXr18/Gjh27349lxYoVlpCQYJMmTYo5980337SEhAR788036/y4gO8rISFhr/7nO39fffVVGzp0qOXn51tSUpLl5+fboEGD7N57791jXz/+8Y+/85gmTZpkCQkJtmLFir16DX/605/iujaB+mhv7n2FhYU2bNiw73yuWO8/Tz/9tP3+97+P88ihUPjthZdfftn69+9vW7dutfHjx9uMGTPsgQcesAEDBtjkyZMP9OEBh4xZs2bV+t/pp59uKSkpe8R79erlzH/44Yft1FNPtczMTPvDH/5gr776qv3mN7+xrl272j/+8Y+4jumMM86wWbNmWcuWLffq8RR+OFTU9b2vV69e3uv32yj89o1GB/oADgbjx4+3du3a2auvvmqNGv3vLbvwwgtt/PjxB/DIgENL3759a/27WbNm1qBBgz3iyj333GMnnHDCHkXepZdeatXV1XEdU7NmzaxZs2bf+bjy8nJLTU2Nax9AfVTX977MzMy9upa5lvYtvvHbC8XFxZabm1vrxN+tQYP/vYWTJ0+2oUOHWsuWLS0lJcW6du1qt9xyi5WVldXKufzyyy09Pd0+//xzO/300y09Pd1at25tY8eOtcrKylqPXb16tZ1//vmWkZFhTZo0sQsuuMDWrl27x3F88MEHduGFF1phYaGlpKRYYWGhXXTRRVZUVFRH7wJQ/xUXF8tv5r55rX7Tk08+aV27drXU1FQ74ogjbNq0abW2u37VO2jQIOvevbu9/fbb1r9/f0tNTbUrr7zSCgsL7eOPP7a33nqr5tfShYWFdfXygP1qb+99u02fPt169eplKSkp1qVLF3v88cdrbXf9qnf3/XDhwoU2dOhQy8jIsMGDB9ugQYPs5ZdftqKiolp/5oHvj8JvL/Tr18/mzJlj119/vc2ZM8eqqqqcj/vss8/s9NNPt8cee8ymT59uP/nJT+zZZ5+1M888c4/HVlVV2VlnnWWDBw+2qVOn2pVXXmkTJkyw3/zmNzWPqaiosJNPPtlmzJhh99xzjz333HPWokULu+CCC/Z4vhUrVljnzp3t97//fc2vt9asWWPHHHOMbdy4se7eDKAe69evn/3zn/+0cePG2fz5823Xrl3ex7/88sv2hz/8wX71q1/ZP//5T8vOzrazzz7bli1b9p37WrNmjV1yySU2cuRIe+WVV+zaa6+1F154wdq3b29HHXVUza+lX3jhhbp6ecB+tbf3PjOz+fPn29ixY+3GG2+0qVOnWs+ePe2qq66yt99++zv3s2PHDjvrrLPspJNOsqlTp9qdd95pf/rTn2zAgAHWokWLWn/mgToQ4Ttt3LgxOu644yIzi8wsSkxMjPr37x/dc889UWlpqTOnuro6qqqqit56663IzKL58+fXbBs1alRkZtGzzz5bK+f000+POnfuXPPvhx56KDKzaOrUqbUeN3r06MjMookTJ8pj3rlzZ7Rt27YoLS0teuCBB2riM2fOjMwsmjlzZgzvAHBgjBo1KkpLS9vrx3/++edR9+7da67VlJSUaPDgwdEf/vCHaMeOHbUea2ZRXl5etHXr1prY2rVrowYNGkT33HNPTWzixImRmUXLly+viQ0cODAys+j111/f4xi6desWDRw4cO9fJFBP7e29r23btlFycnJUVFRUE6uoqIiys7OjMWPG1MRc95/d98PHH398j/2fccYZUdu2bffJawsZ3/jthZycHPvPf/5jc+fOtXvvvdeGDx9uS5cutVtvvdV69OhR843asmXLbOTIkdaiRQtr2LChJSYm2sCBA83MbMmSJbWeMyEhYY9vAnv27FnrV7MzZ860jIwMO+uss2o9buTIkXsc47Zt2+zmm2+2jh07WqNGjaxRo0aWnp5uZWVle+wbOJhFUWQ7d+6s9b/dOnToYPPnz7e33nrL7rzzTjv55JNt7ty59uMf/9j69etn27dvr/VcJ554omVkZNT8Oy8vz5o3b75XfyKRlZVlJ510Ut29MKCe2dt7n5nZkUceaW3atKn5d3JysnXq1Gmv/9zo3HPPrfPjhxvNHTE4+uij7eijjzazr39Ve/PNN9uECRNs/Pjxdvvtt9vxxx9vycnJ9v/+3/+zTp06WWpqqn311Vd2zjnnWEVFRa3nSk1NteTk5FqxpKSkWjem4uJiy8vL2+M4WrRosUds5MiR9vrrr9ttt91mxxxzjGVmZlpCQoKdfvrpe+wbOJg98cQTdsUVV9SKRVFU8/8bNGhgJ5xwgp1wwglmZlZWVmZXXXWVTZ482R5//HG79tprax6bk5Ozx/MnJSXt1TWzt12+wMHOd+/b3eTxfa6l1NRUy8zMrNuDhkThF6fExES74447bMKECbZo0SJ74403bPXq1fbmm2/WfMtnZlZSUhL3PnJycuz999/fI/7t5o4tW7bYtGnT7I477rBbbrmlJl5ZWWmbNm2Ke/9AfXTmmWfa3Llz9/rxaWlpduutt9rkyZNt0aJFdXYc/KE5QvTte19d4Frav/hV715Ys2aNM777V6j5+fk1J25SUlKtxzzyyCNx7/fEE0+00tJSe/HFF2vFn3766Vr/TkhIsCiK9tj3o48++p1/3A4cbHJycmq+gfjmNxFme3et7mt7+y0HUN8d6OuJa2nf4Bu/vXDKKadYQUGBnXnmmdalSxerrq62jz76yO6//35LT0+3G264wfLz8y0rK8t+9KMf2R133GGJiYn2t7/9zebPnx/3fi+77DKbMGGCXXbZZXb33XfbYYcdZq+88oq9+uqrtR6XmZlpJ5xwgv32t7+13NxcKywstLfeessee+wxa9q06fd89cDBo1u3bjZ48GA77bTTrEOHDrZ9+3abM2eO3X///ZaXl2dXXXXVPj+GHj162N///nebPHmytW/f3pKTk61Hjx77fL9AXdube9++1KNHD3v++eftoYcest69e1uDBg1q/Yce4kPhtxd++ctf2tSpU23ChAm2Zs0aq6ystJYtW9rJJ59st956q3Xt2tXMvh4NMXbsWLvkkkssLS3Nhg8fbpMnT97rKeXflpqaam+88YbdcMMNdsstt1hCQoINHTrU/v73v1v//v1rPfbpp5+2G264wf7v//7Pdu7caQMGDLDXXnvNzjjjjO/9+oGDxb333muvvvqq3X333bZ27VrbuXOntW7d2kaOHGm/+MUv9svf5d155522Zs0aGz16tJWWllrbtm33erk3oD7Z23vfvnLDDTfYxx9/bD//+c9ty5YtFkVRrb/nRXwSIt5FAACAIPA3fgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQFD4AQAABGKvBzizlh4ORfVxjGUo19ovfvELuW3AgAHO+OrVq2XOt5cs3K1Zs2Yyp6yszBnfvHmzzFHrX3fs2FHmvPLKK874o48+KnMONVxrdcO3GtPWrVud8WeeeUbmzJs3zxm/7777ZM7OnTvltlg1btxYbjvxxBOd8QsvvFDm/PznP3fGt2zZInPKy8vltoPRd11rfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAJ0V7+xe3B+EewwHc51P/g3Pdc8bz2zp07O+M333yzzBk+fLgzrhorfNvS09NlTnFxsTM+ZswYmaOaOH7zm9/InB/84AfO+Icffihz2rVr54yXlpbKnIkTJzrj48ePlznx/JG6Okfq+to41K+1Bg309yjV1dXOuK9RY9CgQc54Xl6ezJkzZ44z7jtnjj/+eGd88eLFMic5OdkZv+uuu2TOZZdd5oy3atVK5rRp08YZX7t2rcwZOnSoMz548GCZU1JS4oxPmTJF5tRnNHcAAADAzCj8AAAAgkHhBwAAEAgKPwAAgEBQ+AEAAASCwg8AACAQjHNB0A71ERPxuP/+++W2IUOGOONqXIWZHjGya9eu2A7M/Ovhzp071xk/66yzYt6PbyyFGg/zySefyBy1HmlqaqrMSUlJccYrKipkzvvvv++M//CHP5Q5+8uhfq3FM85FrUXre75Vq1bFnLN06VKZ87e//c0Z7969u8xRo5OaNGkic3bs2OGM+943lTNixIiYc3JycmROz549nXHfmt2vvfaa3HagMc4FAAAAZkbhBwAAEAwKPwAAgEBQ+AEAAASCwg8AACAQdPUiaIdKp6HK8b2+zp07O+Oqy8/MrKyszBn3deapjtadO3fKHNUF2bBhQ5mTlJTkjBcVFcmcDRs2OOOqy8/MLCsryxlX742Zfn98nc1qm++9btasmTN+zz33yJxHHnlEbqtLh8q1Fg/1MzvllFNkjjpvk5OTY96P7xqoqqpyxl988UWZU1BQ4IyXlpbKHNXx67turr76amd83rx5Mqd9+/bOuPocMjPbsmWLM+77HJg6daoz7ptwsL/Q1QsAAAAzo/ADAAAIBoUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEA0OtAHcCjwjZhQIxnU6Akzs/vuu88Z97Wjq0WzfYtzv/HGG854SUmJzNm6dasz7lsAW70/nTp1kjnr1693xn2vJ2TxjMq45JJLnHHfuBC1zZejrgHfKA31euI5tl69eskcdW5u375d5qjxE40a6Y/TeBaoV8/ne9/U58CQIUNkzv4a5xKy1NRUZ9x3nmVmZsaco7bl5eXJnC+//NIZP/nkk2XOf//7X2e8S5cuMmfRokXO+PHHHy9z1HXTsWNHmaPeA9/9U92/cnNzY85RI6LqE77xAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBA0NV7gHTu3Fluu+CCC5xxX1eSWgDb59NPP3XGfce2bds2Zzw9PT3mHNWxZWZWXl7ujF933XUyZ8qUKc64r9syZGeeeaYzXlFRIXNUF6yvq1htU52OZrqjsbKyUuao80l1iJvpjmPfOaNyVMe7mVlWVpYz7lvQPZ6JAKrjt7CwUOa0atXKGV+1apXMQWwyMjKccd+1ps4N32etOgd951lBQYEzvnr1apnTp08fZ/ytt96SOeedd54z7utsV5MffJ8D6vrwXdP5+fkx74euXgAAANR7FH4AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEAjmXNQBNXbBZ8GCBXJb8+bNv8/h7DU1MmPUqFEy57XXXnPGP/nkE5nz6quvOuNdu3aVOWrEwM9+9jOZo8a5+MYFHOqOPvpouU2NePCNZlHjQqqqqmSOGmVRVFQkc6ZOneqM+16PGnPhGxujxtP4Rg2p51PvjZl+rxMTE2VOPKNm1Bgk37inIUOGOOOTJk2SOYiNev99o3nU55ZvNIs6N9V5YWa2c+dOZ7xFixYyp6yszBk/5ZRTZI76TPedz6Wlpc6473xW70GzZs1kjhqVpvZvpse5HAzCvSMCAAAEhsIPAAAgEBR+AAAAgaDwAwAACASFHwAAQCDo6o2B6j5SXVE+vg6j/bXIs1rQ+8EHH4z5uX73u9/JbaprcMWKFTLn//7v/5zx++67L6bjMvN3nB7qzj//fLnN102nqC5U32LmqkPW171+9tlnO+OtW7eOeT8+Kkd1+ZmZbdq0yRn3LVB/5plnOuO+n4E6b32dwKpL2dcJOnz4cGecrt66o37Ovp9/+/btnfGFCxfKHPVz9p3PycnJzrjqxjeL756nupSzsrJkjurQVcdspjuYfa9HbfN9rsXzHtQXfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAgE41y+xTcqIZ6xIGvWrHHGN27cKHPUYvO+hba7desW24HF6cknn3TGL7nkEpkze/ZsZ7xfv351ckzfJYqi/bKf+mjo0KFymzqffSMm1LgQ37WhFqKvqKiQOeoYli1bJnPUuIht27bJnHjGX6jxE6eeeqrMUdf0li1bYj429X6a6fE0ZWVlMudgXmz+YKHOJzWuxMysZ8+ezvi8efNkjhoxkpaWJnMyMzOdcXU9melz0/fZoc5N336aNGnijCckJMic7du3O+OdOnWSOcXFxc647/NGjZaK533b3/jGDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACEWxXr+oKimfh5bvuuktumzNnjjPeoUMHmaOO7fDDD5c5Rx99tDP+xRdfyJy//e1vzrivs/nkk092xn/5y1/KnLvvvltui5Wvm0tt83VZHSrU+bRr1y6Zo7rEVeeume7a83XBqufznZtTp051xq+66iqZU1JS4oyrjloz3Vns+xxQXYObN2+WOarr2bdwvOqC9HX3q/2oYzYzy8vLc8b79u0rc1SnPtzUdePrglXnre9nGc9+FHX+mcX3mRpPR6v6TI/nc61NmzYyp2nTps64r6tXdUr7OrV9Ewb2p0P/jggAAAAzo/ADAAAIBoUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEAEO85FtaP72sTVyArfKJNp06Y549dff73Mefjhh53x0aNHy5y5c+c6459++qnMUWMBunTpInNOOeUUZ3zGjBkyR/GNZomiKKa4b1t9WRh7XzrttNOccd9onmbNmjnjvp9LUlKSM+4b/VBaWuqMt2zZUuaocz0rK0vmqPEXvmtajWRQr9PMbNWqVc74li1bZI4at7R69WqZk5yc7Izn5OTIHDXKwve+VVZWOuODBg2SOYxziY26d/hG87Rr1y6m5zIzS0lJccZ941zUtnhGtviuG/U57PuMUqOgfNe0+hzYsGGDzMnPz5fbFHUdqvFIZoxzAQAAwH5G4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEAdNV6+vwyierk1fV5AyadIkZ9zXqaMWjp85c6bM+fjjj53xv/zlLzJH6dixo9y2YMECZ9zXoRtP967i69CtS77FuQ8Vf/jDH5zxiRMnypzDDjvMGVcdwmZmw4YNc8azs7Nljur49XXSbdq0yRlXHahm/g5JRXUw+zqbd+7c6YxnZGTIHNWdqLqKzXT35qxZs2TO4sWLnfF33nlH5rz99tvOeFlZmczBnlQXtpn+OfveY5WjOnfN9H3Nd/9U56aPuuf69qO6d+OZIqAmUpjp923ZsmUy54gjjojpucz0Z56almBm9sUXX8ht+xPf+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAnHQjHOJZ2SLb/HnqqoqZ/yEE06QORdddJEzPnLkSJlzww03OONvvfWWzFGjLHzOO+88Z9z3Hjz99NMx56jW+7oezaJa5a+++mqZM27cOGd8/fr1dXFIByXfuIiPPvoopriZ2T333OOMP/roozLn+OOPd8Y//PBDmfP+++8744MGDZI58YylUHyfN126dHHGt27dKnPUNe271tSYqLPPPlvm4MBJTU2V29RoHt8oMDUaxbef0tLSmPZvpkfANGqkywN1rfnGufiOQVHP57tu1L3I93pat27tjPvGvqmxTi1btpQ59QXf+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAIA6arl4f1fmjOnd9HnroIbntH//4hzPu6+pV3U++7uHnn3/eGZ83b57Muemmm2Lav5nZokWLnPH27dvLnE8++cQZ79y5s8zJzMx0xu+9916Zc8011zjjvg7dLVu2OOP//e9/ZY7q5jrY+BY6jzUnng76rKwsuU39zHzdiV27dnXGmzRpInNUp5/v9cSz2Lzq5lu9erXMUe+PbxF4tZ94+D4HVBdkPOdByHydpklJSc6477pV53pOTo7MKS4ujvnY1DH4chRf56w6n33vQTxdvdu3b49p/2b6OiwvL5c5n332mTOen58vc+oLvvEDAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAATikBjnolrId+zYIXMuuugiZ9w3LiQ9Pd0Z79ixo8xR29ToETOzY4891hn3tbBnZ2fLbcqnn37qjK9cuVLmHHbYYc64731TowwyMjJkzldffeWMV1ZWyhz186nLsRj1lRrJUdc5SjyjH5o2bSq3NWvWzBkvKyuTOWvWrHHGk5OTZc62bdvkNuX11193xo877jiZo8ap+MasxDOOSvGNZqnL8yBkKSkpcpu6R+Xm5soc9fP3fQaqY/CNTIln1Iw6b9VzmflHJCmNGzd2xuMZ0eQbt6TGlB111FEyp7Cw0BlfuHChzKkv+MYPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJxSHT1xrNAvepk69Spk8xRCzm/8cYbMkc939SpU2VO69atnfGKigqZoxaMVp2uZrrrOTU1VeYoqgvTzGzatGnOeMuWLWVOXl6eM+7rQFSLmu/atUvmoG74FmdXfNftrFmznHHfAujq5+/r6m3evLkz7utS7tatmzO+bt06mbN582Zn3NfZ7ptKgPonMzNTblOdpuqz3sysvLzcGZ83b57MOfLII51x3/kcz7UbT4eu4js2X/euoo5N3b/N9HXo+4xS12dOTo7MUV3K+/ta5xs/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgDolxLvEsZv7yyy8743/84x9lzl//+ldn/LrrrpM5K1eudMZLSkpkjlr82TeWZMuWLXKbosZf+EZMfPjhh874KaecInM2bNjgjPveg40bNzrjvjECaiyAbwxOyNSoAt/InLqkRvaYmX355ZfOeP/+/WWOGpniG5VQVlbmjKtF6M30+VRZWSlzcnNznXHfNV1aWiq3xWp//UxDpkZ1+PjGbann852bajSL7x6p9uP7rK3LcS6+51Kvx/deq22rVq2SOerzxvcZtXPnTmfcN9pMvR7GuQAAAGCfoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEIiDpqvXt1iyb5uiOuYKCgpkjurmmzlzpsz51a9+5YyrxeHNdIeR6gw0M9u0aZMzrjp3zXT37rPPPitzLrjgArktVsXFxXJbamqqM64WLjfTXVbxnB+IjXrvzXQX4htvvCFz1Ln+7rvvyhxfl7iirgHf61Edkr5uy/z8fGfc13HuOwbUP0lJSXJbcnKyM+7r5lTdri1atJA5qku9adOmMkd1mvqoc933XOr1+HLUe+q7btR+fNMqVqxY4Yx37NhR5qifne++Fs97vS/wjR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQFD4AQAABILCDwAAIBD1o7f4G1S7s2+0gW+h81j52sSVF154QW5buHChM/7ZZ5/JHDXq5auvvpI5amHoli1bypwf/vCHzvhjjz0mc5TevXvHnOP7uVVXVzvj8YwNwb6nfl4+vvFEHTp0iPn51IL3vvNMjYvwnWdq1FBiYqLMUWM2KisrZU6XLl3ktlj5RhpFUVRn+wlZZmam3KZGjPjGueTk5MR8DOr+6Rs1oz431TH7tvnGlahrqnHjxjEfm+/zRm3Ly8uTOf/+979jzlHjYbZs2SJzUlJSnPGtW7fKnH2Bb/wAAAACQeEHAAAQCAo/AACAQFD4AQAABILCDwAAIBD1rqs3noXJjz32WGf8Jz/5icx57733nPE//OEPMe/f5/PPP3fGBw4cKHNUJ5Na6N3M7KmnnnLGf/nLX8qceLp3lbS0tJhzfN2WqjvM1zWmurl8HY2oG77OULXNtwC66n7z/fxVh6zvPFPXmi9HnU/xdEH6Pu/UexAP37HV5VQEuKnPx4KCAplTXFzsjPu6Rtu1a+eM+7pg4+nqVdear0M3OTnZGfdd0+qzw3e/qaqqcsbLy8tljpoIcNVVV8mcadOmOePr16+XOXV5TX8ffOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAjEXo9zUS3f8SzK7BsfoBamXrRokcypqKhwxn2t02eeeaYz7muvv+WWW+S2WL399tsx5/hGZrzzzjvO+N133x3zfuJZ0D2eBcV9i9orvhEDSjwjgkLgO59itX37drlNfXaokRC+bb7F5tWC975zRn1+qefy5fjOM3XcvhETjCE6uPjuhWrMie9zc9myZTEfgzrPfNeaGn/iez3qs9uXo65D36iZeO7t8RybOgbf9blu3Tq5TcnOznbGV6xYEfNzfR984wcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgdjrrl7ViVvXC3xnZGQ446obxszs888/d8ZVt5KZ2datW53xH/3oRzJHdRY/9dRTMiceCxcujDnn+OOPr7P9x9Pt2aJFC7lt27Ztzrjq9jTTHZK+Tke1zdeZhbrh68xTPxdfjurM83Xoqv3E06Ve1x21aj++a+CLL75wxtVi92b+7mrsW76fpTqf8/PzZc7UqVOd8SZNmsgc1b3rOy+ysrKccd/1qfaTmpoqc5o2beqM+2qI0tJSuU1R931VW5iZffjhh864qi3MdEd2WVmZzKkvEyb4xg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEIi9HudSWFjojN94440yZ8uWLc64r0VatYNv3rxZ5qiFqX2t02rBZjXmxczsySefdMY/+ugjmaNGwEycOFHmqNEoXbt2lTmKGiNgptve48nxjdmI9bnMdIu/byyB+nnHc2whUCNL4hnnk5ubK7epn2U8o1l8x1aXOXV9zqhj8O2ncePGznheXp7MKSoqimn/qDvqnmKmr4FmzZrJHHWfbNeuncxRI0vS0tJkTkFBgTOuRraY6ZElvv2oMUS++416Pt/onMzMTGc8JSVF5rRs2dIZ37Fjh8xR9xvf6/GdI/sTd0QAAIBAUPgBAAAEgsIPAAAgEBR+AAAAgaDwAwAACMRet5h06tTJGT///PNlzpw5c5zx2267bW93W0N1CJvpjkJf54+yYcMGuU0tGL1w4UKZo7qR1cLYZmYXXnihM/7JJ5/IHNWd6OucVXyLcytt2rSR21Rnlm/RbNVl5VvQW/28fccWsrrs6vWdz6r7LZ7rM55O4HjOZ/VcZvr98eUovvdAPV88Xb3xHBti4/tsUteA6o41M1u1apUz3r59e5nz5ZdfOuPbtm2TOUuXLnXGfdeNug59OapL2Nfpqu4dvvt0kyZNnHHfdVNcXOyMjxs3TuaMGTPGGfd9FtYXfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAjEXo9zmTFjhjOuxm7UtdTUVLlNLXTdq1cvmdO6deuYnsvMLDs72xn3tW+r9vo777xT5lRUVMhtSjwjJupy4fa//OUvcptqlfctAq5G9PjG06htjz76qMxZv3693Ia95xvNo0YaxTNixDcuIp7nUzm+ERPqPKvra61x48bOuO8zCgeO72esxp906NBB5qjxXb6xXqhbO3bskNvUfdo31keNmtnf+MYPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAKx1129B1p5ebncphYmV/GQxNNN6OtKUj7//HO5bfz48TE/Hw4uK1askNuaNm3qjPvOzXjOQfV8O3fulDkNGzZ0xn0duurYfB3Haj++90Adg1q43kd1lZrF915jT74pBepnlp6evq8OpxZfl3p9pq4p3/kcD/UZ8YMf/EDmtGnTxhl///33Zc7++nl/F77xAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAE4uDs8QbwvflGlsSa41t8vHHjxs54RkaGzFGjMVJSUmSOWlBdjVLxbUtMTJQ5qampzrhvNIvaT1lZmcxRox+6desmc3DgqLFFZmbNmzePOSceasyJb6TRwcg3Okm9B/GMgPnyyy/ltu7duzvjL7zwgswpLCyM+Rj2Bb7xAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBA0NULYK+pTtyKigqZs27dOmc8KSlJ5qhF7X2dyNu2bXPGs7KyZI7qdlTPZaY7jn3dw6ob2fe+LVu2zBlfvHixzFEOta7O+ujNN9+U27766itnvFWrVnV6DL5u11Co9yCe9+bll1+W22bOnOmMf/zxxzLn3XffjfkY9gW+8QMAAAgEhR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQFD4AQAABCIh8q0sDgAAgEMG3/gBAAAEgsIPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABAICr99YMGCBXbFFVdYu3btLDk52dLT061Xr142fvx427Rp0z7Z53vvvWfjxo2zkpKSffL8wL4wZ84cO/vss61NmzaWlJRkeXl51q9fPxs7duyBPjQzMyssLLRhw4Yd6MMAvpdJkyZZQkJCzf8aNWpkBQUFdsUVV9iqVatifr6EhAQbN25czb/ffPNNS0hIsDfffLPuDhr7DIVfHfvLX/5ivXv3trlz59rPfvYzmz59ur3wwgt23nnn2cMPP2xXXXXVPtnve++9Z3feeSeFHw4aL7/8svXv39+2bt1q48ePtxkzZtgDDzxgAwYMsMmTJx/owwMOORMnTrRZs2bZa6+9ZqNHj7ZnnnnGjj/+eCsrKzvQh4b9qNGBPoBDyaxZs+yaa66xIUOG2JQpUywpKalm25AhQ2zs2LE2ffr0A3iEQP0xfvx4a9eunb366qvWqNH/PoouvPBCGz9+/AE8sv2nvLzcUlNTD/RhIBDdu3e3o48+2szMTjzxRNu1a5fdddddNmXKFLv44osP8NHtOxUVFZacnGwJCQkH+lDqBb7xq0O//vWvLSEhwf785z/XKvp2a9y4sZ111llmZlZdXW3jx4+3Ll26WFJSkjVv3twuu+wyW7lyZa2c1157zYYPH24FBQWWnJxsHTt2tDFjxtjGjRtrHjNu3Dj72c9+ZmZm7dq1q/k6n6/dUZ8VFxdbbm5uraJvtwYN/vfRtPvXrdOnT7devXpZSkqKdenSxR5//PE98tauXWtjxoyxgoICa9y4sbVr187uvPNO27lzZ63H3XnnndanTx/Lzs62zMxM69Wrlz322GMWRdF3Hvef/vQna9Sokd1xxx01sX//+982ePBgy8zMtNTUVBswYIC9/vrrtfLGjRtnCQkJ9uGHH9qIESMsKyvLOnTo8J37A/aVvn37mplZUVGRDRo0yAYNGrTHYy6//HIrLCyM6/lffPFF69evn6WmplpGRoYNGTLEZs2aVbN9ypQplpCQsMe1Ymb20EMPWUJCgi1YsKAm9sEHH9hZZ51l2dnZlpycbEcddZQ9++yztfJ2/1p7xowZduWVV1qzZs0sNTXVKisr43oNhyIKvzqya9cue+ONN6x3797WunXr73z8NddcYzfffLMNGTLEXnzxRbvrrrts+vTp1r9//1pF3RdffGH9+vWzhx56yGbMmGG33367zZkzx4477jirqqoyM7Mf/vCHdt1115mZ2fPPP2+zZs2yWbNmWa9evfbNiwXqQL9+/WzOnDl2/fXX25w5c2rOZ5f58+fb2LFj7cYbb7SpU6daz5497aqrrrK333675jFr1661Y4891l599VW7/fbb7V//+pddddVVds8999jo0aNrPd+KFStszJgx9uyzz9rzzz9v55xzjl133XV21113yWOIoshuuukm+8lPfmKPPvqo3XnnnWZm9tRTT9nQoUMtMzPTnnjiCXv22WctOzvbTjnlFOcN7ZxzzrGOHTvac889Zw8//HCsbxtQZz7//HMzM2vWrFmdP/fTTz9tw4cPt8zMTHvmmWfsscces82bN9ugQYPsnXfeMTOzYcOGWfPmzW3ixIl75E+aNMl69eplPXv2NDOzmTNn2oABA6ykpMQefvhhmzp1qh155JF2wQUX2KRJk/bIv/LKKy0xMdGefPJJ+8c//mGJiYl1/hoPWhHqxNq1ayMziy688MLvfOySJUsiM4uuvfbaWvE5c+ZEZhb9/Oc/d+ZVV1dHVVVVUVFRUWRm0dSpU2u2/fa3v43MLFq+fPn3eh3A/rJx48bouOOOi8wsMrMoMTEx6t+/f3TPPfdEpaWlNY9r27ZtlJycHBUVFdXEKioqouzs7GjMmDE1sTFjxkTp6em1HhdFUXTfffdFZhZ9/PHHzuPYtWtXVFVVFf3qV7+KcnJyourq6lr7PuOMM6Ly8vLo3HPPjZo0aRL9+9//rtleVlYWZWdnR2eeeeYez3nEEUdExx57bE3sjjvuiMwsuv3222N8p4DvZ+LEiZGZRbNnz46qqqqi0tLSaNq0aVGzZs2ijIyMaO3atdHAgQOjgQMH7pE7atSoqG3btrViZhbdcccdNf+eOXNmZGbRzJkzoyj6+vzPz8+PevToEe3atavmcaWlpVHz5s2j/v3718R++tOfRikpKVFJSUlNbPHixZGZRQ8++GBNrEuXLtFRRx0VVVVV1TqWYcOGRS1btqzZz+7Xetlll8X6NgWDb/wOgJkzZ5rZ11+hf9Oxxx5rXbt2rfUtwfr16+1HP/qRtW7d2ho1amSJiYnWtm1bMzNbsmTJfjtmoK7l5OTYf/7zH5s7d67de++9Nnz4cFu6dKndeuut1qNHj1rffB955JHWpk2bmn8nJydbp06drKioqCY2bdo0O/HEEy0/P9927txZ87/TTjvNzMzeeuutmse+8cYbdvLJJ1uTJk2sYcOGlpiYaLfffrsVFxfb+vXrax1ncXGxnXTSSfb+++/bO++8Y4MHD67Z9t5779mmTZts1KhRtfZZXV1tp556qs2dO3ePP5w/99xz6+YNBGLUt29fS0xMtIyMDBs2bJi1aNHC/vWvf1leXl6d7ufTTz+11atX26WXXlrrzzbS09Pt3HPPtdmzZ1t5ebmZff3NXEVFRa2GrokTJ1pSUpKNHDnSzL7+ZvKTTz6p+TvEb15rp59+uq1Zs8Y+/fTTWsfAdabR3FFHcnNzLTU11ZYvX/6djy0uLjYzs5YtW+6xLT8/v+ZmVl1dbUOHDrXVq1fbbbfdZj169LC0tDSrrq62vn37WkVFRd2+COAAOProo2v+4LyqqspuvvlmmzBhgo0fP76mySMnJ2ePvKSkpFrXwLp16+yll16Sv9LZXUi+//77NnToUBs0aJD95S9/qfl7wClTptjdd9+9x3W1dOlS27x5s40ePdq6d+9ea9u6devMzGzEiBHy9W3atMnS0tJq/u267oH94a9//at17drVGjVqZHl5efvsXPyue1x1dbVt3rzZUlNTrVu3bnbMMcfYxIkT7eqrr7Zdu3bZU089ZcOHD7fs7Gwz+991dtNNN9lNN93k3Oc3/0NR7Rtfo/CrIw0bNrTBgwfbv/71L1u5cqUVFBTIx+6+ia1Zs2aPx61evdpyc3PNzGzRokU2f/58mzRpko0aNarmMbv/LgM41CQmJtodd9xhEyZMsEWLFsWUm5ubaz179rS7777buT0/P9/MzP7+979bYmKiTZs2zZKTk2u2T5kyxZnXr18/O++882pGMT300EM132LsvlYffPDBmj+U/7Zvf5tCZyEOlK5du9b8R9a3JScn25YtW/aIf7ug2hvfvMd92+rVq61BgwaWlZVVE7viiivs2muvtSVLltiyZctszZo1dsUVV9Rs332d3XrrrXbOOec499m5c+da/+Y60yj86tCtt95qr7zyio0ePdqmTp1qjRs3rrW9qqrKpk+fbieddJKZff1H4cccc0zN9rlz59qSJUvsF7/4hZn978T9dofwI488sse+dz+GbwFxsFizZo3zv8p3/wnD7kJtbw0bNsxeeeUV69ChQ62byrftHmDbsGHDmlhFRYU9+eSTMmfUqFGWlpZmI0eOtLKyMnviiSesYcOGNmDAAGvatKktXrzYfvzjH8d0vEB9UlhYaM8995xVVlbW3E+Ki4vtvffes8zMzJieq3PnztaqVSt7+umn7aabbqq5l5WVldk///nPmk7f3S666CL76U9/apMmTbJly5ZZq1atbOjQobWe77DDDrP58+fbr3/96zp4tWGj8KtDu7tvr732Wuvdu7ddc8011q1bN6uqqrJ58+bZn//8Z+vevbu98MILdvXVV9uDDz5oDRo0sNNOO81WrFhht912m7Vu3dpuvPFGMzPr0qWLdejQwW655RaLosiys7PtpZdestdee22Pfffo0cPMzB544AEbNWqUJSYmWufOnS0jI2O/vgfA3jrllFOsoKDAzjzzTOvSpYtVV1fbRx99ZPfff7+lp6fbDTfcENPz/epXv7LXXnvN+vfvb9dff7117tzZtm/fbitWrLBXXnnFHn74YSsoKLAzzjjDfve739nIkSPt6quvtuLiYrvvvvucI5i+acSIEZaammojRoywiooKe+aZZyw9Pd0efPBBGzVqlG3atMlGjBhhzZs3tw0bNtj8+fNtw4YN9tBDD32ftwnYLy699FJ75JFH7JJLLrHRo0dbcXGxjR8/Puaiz+zrcUzjx4+3iy++2IYNG2ZjxoyxyspK++1vf2slJSV277331np806ZN7eyzz7ZJkyZZSUmJ3XTTTbX+NtDs6y88TjvtNDvllFPs8ssvt1atWtmmTZtsyZIl9uGHH9pzzz33vV5/UA50d8mh6KOPPopGjRoVtWnTJmrcuHGUlpYWHXXUUdHtt98erV+/Poqir7uefvOb30SdOnWKEhMTo9zc3OiSSy6Jvvrqq1rPtXjx4mjIkCFRRkZGlJWVFZ133nnRl19+uUdXVRRF0a233hrl5+dHDRo0qNVhBdRHkydPjkaOHBkddthhUXp6epSYmBi1adMmuvTSS6PFixfXPG53Z+23uboQN2zYEF1//fVRu3btosTExCg7Ozvq3bt39Itf/CLatm1bzeMef/zxqHPnzlFSUlLUvn376J577okee+yxPTrjXfueOXNmlJ6eHp166qlReXl5FEVR9NZbb0VnnHFGlJ2dHSUmJkatWrWKzjjjjOi5556rydvd1bthw4bv87YBMdvd6Tp37lzv45544omoa9euUXJycnT44YdHkydPjqurd7cpU6ZEffr0iZKTk6O0tLRo8ODB0bvvvuvc94wZM2o6/JcuXep8zPz586Pzzz8/at68eZSYmBi1aNEiOumkk6KHH3445tcasoQo2ouJpQAAADjoMc4FAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBA7PXKHax7Z7WWmPmmLl26yJxvL+q+W7t27WSOWm5q+fLlMufbU853e+GFF2TOihUr5LZQ1McxllxrOBRxrR04LVq0kNsuueQSZ/yHP/yhzPniiy+c8XfeeUfm/Oc//5HblLFjxzrjhx9+uMz505/+5Iw//fTTMmfDhg2xHVg9913XGt/4AQAABILCDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgEqK9bLU6GLufGjXSTcs7d+50xn/84x/LHLVt8+bNMkd1/PreT9Whu2bNGpmzatUqZ7xHjx4yJy8vzxmvrq6WOYmJic54VVWVzKnP6DQE9g+utbrRt29fue3iiy92xnNzc2VOUVGRM37EEUfInG7dujnj+fn5Mqe8vNwZ991v1M/nvffekzmffPJJzMe2bds2Z/zxxx+XOe+++67cpqjXU9fXBl29AAAAMDMKPwAAgGBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIxCExzkWNP/G1ibdt29YZnzZtmsxRLfG+cS4NGzZ0xn2t5Wo0ihrZYmaWlJTkjKelpcmc1157zRm//PLLZY6iXqeZ2a5du2J+vv2FERPA/sG1Fpurr77aGe/du7fMKSsrc8a3bt0qc9T9c8mSJTInNTXVGU9OTpY56enpzrg6ZjM9wiwzM1PmNG3aNOZjU68nJydH5ixYsMAZf/jhh2XO/sI4FwAAAJgZhR8AAEAwKPwAAAACQeEHAAAQCAo/AACAQBwSXb3xUB05lZWVMmf79u3OuK9bSG378ssvZU7r1q1j3k9JSYkz7uvmKigocMbVItdmZj/4wQ/ktoMRnYbA/sG1Fptf/epXznjjxo1lzo4dO5xx34SLiooKZ1x1x5rpe9H69etlTkZGhjPu6+r13fMUNeFi27ZtMqe0tNQZz87OljlqWsW4ceP0we0ndPUCAADAzCj8AAAAgkHhBwAAEAgKPwAAgEBQ+AEAAASCwg8AACAQjQ70AexLffv2ldsaNXK/9I0bN8qcxMREZ1y1gpvpMSvNmzeXORs2bHDGy8vLZY5q8fe1/n/11VfOeNeuXWVO9+7dnfFFixbJHADAnnJzc+W2zp07O+PLly+XOWo8TYMG+jseNebEN0pF5fj2o+6fvv3s3LnTGVej1XzU/s3M0tLSnHFVJ/hy8vPzZc7q1avltv2Jb/wAAAACQeEHAAAQCAo/AACAQFD4AQAABILCDwAAIBCHdFfviSeeKLepBZZ9HUZq4WPfQt+qk0gtpm2mO3F9Cy9XVlbG9Fxm+ri3bt0qc84//3xnnK5eAIhNhw4d5LaioiJnvKqqSuao+43v3pGVleWM++5rvm5XRd1z1eQLM7OmTZs64+np6TJHdfz6pm+0bNnSGVddxT6+iR109QIAAGC/ovADAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEAc0uNc+vTpI7ep9vaGDRvKHNUm7hvNkpKSEtNzmelWed+xKUlJSXKbav33tbAfe+yxMR8DAGBPHTt2jDmnRYsWctuaNWuc8XXr1smcVq1aOeO++1o81H2tSZMmMkfdp7ds2SJz1PtTXV0tc9SIHPXemJlt3rzZGT/yyCNlzkcffSS37U984wcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgTiku3rz8vLkNtVhlJOTI3NWrVrljPsWs1adURkZGTKnsrLSGVeLXJvpjiXVuWumu598C0nH04UGANiTr2tUfab7umAPP/xwZ/x3v/tdzMfgmwihJj80bdpU5hQVFTnj6enpMe9HTcsw08e9dOlSmTN27FhnXN3zzcyKi4udcV/XdX3BN34AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEAc0uNc1ALPZmaNGzd2xn2t8mph6AYNdP2sFn/2jVlR1JgXM90S7xsBo1riU1NTZY6vxR+IRcOGDeU233mrqLFKP/rRj2TO+++/74yXlpbKnBtuuMEZHzdunMzZsGGD3Kao1+P7XIv1uczM0tLSnPFt27bFvB/ExncNqM/atWvXypyhQ4c640cccYTMUaPNysvLZY46B0tKSmSOurf67rlqtFjXrl1ljhoB06dPH5mjxuB88MEHMkfdw33XWn3BN34AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEIhDoqtXdehmZ2fLHNUx5euYU11OqivKx5ejund9OaoTd8eOHTKnoqLCGc/MzJQ5amHqnj17ypwFCxbIbQhXPJ27nTp1ktt+/vOfO+O+DvrTTz/dGf/www9lTnJyckzPZWb2xBNPyG1KPN27ivqMNNOfhdu3b5c5qnMSsfFNSVA//9zcXJmzdOlSZ3zWrFky58QTT3TGfR3H6h7lO2d9UykUda2pbnwzff/67LPPZM7AgQOdcd97rTqO1bSM+oRv/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgTgkxrmoBZtVK7iZbrn2tXwrvnERapyKbyFnNbbF1yqvxiv4Fs2ePXu2M37CCSfIHDV+oEOHDjKHcS5w8S0c///9f/9fzDmrVq1yxn2jLA477DBnvF+/fjJn8eLFzniPHj1kzrBhw5zxl19+WebU5TgX32irtWvXOuPxfEYx5iU2akSYmf6ZZWVlyRw1fuSrr76SOepnVlZWJnPS0tLkNkWNWfHdo9R+2rZtK3PS09Od8Zdeeknm5OTkOONbt26VOevXr3fGfe9bfcE3fgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACQeEHAAAQiEOiq7dz587OuG9h8urqamd8/vz5Mqdv374xPZeZ7vj1deypbmTfflS3ra+zedq0ac64WrTbTL+neXl5Mgf7XoMGdfffcL7zTOnWrZvcdvnllzvjvq5R1WX3+eefy5w2bdo444WFhTJn3rx5zrivU19NEVi5cqXMOeuss5zxY489VuYsX77cGf/iiy9kTqtWrZzxZ599VuaozyLfZ1Q85wj25LtHqY5f37VeUFDgjKsubDOzjIwMZ9x3fapO4O3bt8scRXX7mumu2tTUVJmj7oVNmzaVOa1bt3bGfdeaeq2+e259wTd+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAHBLjXNQoEV+rvOIbyaDawYuLi2WOWjDa18KuFnn2LRitWsjVot1mZitWrHDGfeMC1FiAdu3ayRzUDd94hQM9XuPJJ5+U2+bMmeOML1iwQOZs2LDBGfctDt+8eXNnfMCAATJHXbsbN26UOeq99i0cX1VV5YyrMRJmZn369HHG1ZgPMz3mYujQoTLn3XffdcZ9i80///zzznhlZaXMwZ7U6BEzfZ75PtPVtbZ+/XqZU1JS4oz7RsCUlpY642o0jJm+Pjdt2iRzmjRp4oyvW7dO5qhratmyZTJn9uzZzrgaK2Wmr2nfe1Bf8I0fAABAICj8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAATikOjq9XXeKKojp3379jJHdTJt27ZN5qhOzIYNG8oc1VWrOoR9x6AW0/Y9n2+RadXp5+tOQ92IokhuU+dZixYtZI7qQu3atavMUV21qjPUzCw/P98Z79+/v8zp0KGDM758+XKZM23aNGf8yiuvlDk33nijM+671mbOnOmM+7oGVSemrxu7oqJCblNUN7Tv3OnWrZsz7ps8oLY98sgjnqPDt/k6QNXP33dNf/zxx864r0NXdc5u2bJF5qjrwzfhQj2f7zxT1DGb6fun71pT98mWLVvKnMTERGfc917XF3zjBwAAEAgKPwAAgEBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIRP3vO94LeXl5Meeo9m1fe70aiaAWRjfTY2N8Y1Z8beeKGg/jW9T+mGOOccZ9C3qrUQK+8TSoGxdddJHc1r17d2e8vLxc5qjzzDf6IysryxnftWuXzFHXhxojYmbWpk0bZ3zx4sUyZ+vWrc74O++8I3PmzZvnjG/evFnmqNFJatyTmVlJSYkz7vvsUCN61LgKnx07dshtjRs3dsbVMZuZFRQUxHwMIVOjP3yys7Odcd/4sJUrVzrjvvNs06ZNzrjvPFMjS1JSUmSOukeo69bHd79ZvXq1M960aVOZU1RU5Iy3bt1a5qjPQt9nrjoPVJ2wr/CNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAE4pDo6lWdqzk5OTJn0aJFzrhv8WfVZefraFTdR6qTzkx3W/oWbVfdQr7OvMMOO8wZ93VMqdfq6xpD3fAtzt6qVStn3Nehqzo9v/zyS5mjutF95+aMGTNizlHXoa+jUb0/qmvRdwxt27aVObm5uc646vIzM9u4caMz7uvgb968uTPu+7xRfJ2TqqMxOTlZ5mRmZsZ8DCFTHaW+bk61rbi4WOasWrXKGVdduGa6e3jNmjUyR90jfPdP9XmTlJQkc9S93XcNqOvTd2xffPGFM+6bPKC6d30TO9R5sGHDBpmzL/CNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEIfEOBc1dmDdunUyJz093RlXre1mur3etwC3amHfvn27zFGt8vGMcfAtHK/a231jHNRYCN/i3IhNRkaGMz5hwgSZo0YidO/eXeb07NnTGfeNMlFjPPLz82WOGnvgGzWkRjKo69ZMv29qDJOZvj59183ixYudcd94GrXts88+izlny5YtMkctUN+ggf5vfPVz2Lx5s8xRnxG+UVAhU+eg77NW/fx99yg1msd33ZSVlTnjzZo1kzmKGidjpkeZqJEtZvpcV9etmX5/fPfptWvXOuPqmM3MKisrnXHfaDPfWJ39iW/8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAASCwg8AACAQ9aPF5HtSC537FsBWXai+rhvVSRRFkcxRCzbXdXePej7fIvCqS9jXnaioDifELisryxk/7bTTZM769eud8eXLl8uc5557zhn3dZwrvq5u1eXmW8xcnc++Bd1Vd6JvUXvo99r381Hdu74uyJCpe4Svs119pvquz3nz5jnjvutTbVuzZo3MUV3CalKEmT6ffB266th856bqRvd1D//3v/91xn33QtX573s98Uzm2Bf4xg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEIhDYpyLWkxaLdpupkc/+BYZV9t8Ldq+xdFj3Y9vbEysz2WmW+J9i9qrcQ2tWrWK6bigffnll86471zq0KGDM37kkUfKHPV8vsXM1QiDr776SuZs3LjRGfeNpVDnpu98VqOLcnJyZE7jxo1jipvp8Se+60a9174cNcrCdx6oURK+16M+v9Ri977n+/TTT2VOyNQoEd+5uW3bNmc8OTlZ5qjRRd27d5c56ppW91Uz/RmlRjeZ6VFMRUVFMqdly5bOuG9sUHl5uTOem5srcz777DNn3Pd5o0bXqFE3Zv5xVPsT3/gBAAAEgsIPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAOia7epUuXOuNqsXsz3f3m6wSOpwtWdRr6qO5d337UNt8i06rTbNWqVTLnk08+ccZnzZolc1A3VqxYEfM2X1eaOtd9HXOqY83XAai2qUXozfwLncfK12mo9qM6A305vmNWnx2+DsB49qN+3lu3bpU56vNmw4YNMkd1atflz+1Qorqg4+lsr6qqkjmqQ/bUU0+NeT++n786z3yfN+p+k5+fL3NWrlzpjPs6m1X3ri9n+fLlcpui3jc1McRMvwf7G9/4AQAABILCDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACcUiMc7nmmmtizpk8ebIz7lvUXo0q8LWJqwXv1cLoZnoRdrU4vI+v9V8tGK0WrDYzGzFiRMzHgAPHd56VlJTEFAcQHzXWa/369TKnZ8+ezrhvDJIazeO7R6lRYOreZaZHmfj2o45b3YfMzFq0aOGM+8bgqOdr1aqVzFHvW/fu3WXOwoULnfEFCxbIHPW+7W984wcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgTgkunrjobp1fB1TqstJdQT5tvkWs1bdu74uK9U15stRHb++RbMBALFR3ZxpaWkyR30+FxYWxrx/X7et6oKN5164ZcsWmdOkSRNnvKysTOaobb73TR13ZmamzFE2b94st6l7u69LWd2n9ze+8QMAAAgEhR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQFD4AQAABCLYcS5qYWrfmJV4qJZv3wiYBg1ir8fVuAD1Os3Mdu3a5YynpqbGvH8AQGy2bdsWc86SJUtizmnevLnctnXrVmfcd4/KyclxxlevXi1zfONhFDUaxTcyRd3XfDnKxx9/LLep0SwVFRUx5+xvfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIEItqt36dKlzniHDh1ifi7VUWtm1qiR+y1WnUdmuvNnx44dMsf3fLHuZ+3atTE/FwDArXHjxs6473O7Y8eOznhxcXHM+/d12yYnJzvjvgkXn332mTOuun3N9L1Q7d/MbPny5c54PPfPeLqKN2/eLLcVFhY64wsXLpQ56j3Y3/jGDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACQeEHAAAQiPrRW1yP+BZRTkhIcMYTExNljlroWj2XmW759uWkpKQ442VlZTJHPZ9vcW4AQGyaN28ec862bduc8Y8//jjm52rSpInctn37dmfcN6YsMzPTGS8pKZE5zZo1c8bLy8tlTsuWLZ3xqqoqmaPua2lpaTHnLF68WOYcddRRMT2XmVlubq4z/vnnn8ucfYFv/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEMF29VZUVDjjvq5e1eXUoIGun1WHz44dO2SO6ubydVmpzizfftRr9S20DQCIjeooVRMczPS0iA8//FDmdOnSxRk/4ogjZI56vqSkJJmTnp7ujPsmXFRWVjrjvnuUer4tW7bInMLCQmc8Pz9f5nTu3NkZnzt3rszp06ePM+7r6m3atKnctj/xjR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQFD4AQAABILCDwAAIBCHxDgXNU7FN5pFtdG3aNFC5qgFqH3jXFq3bu2Mr127NuZjy8jIkDmqhVyNhjHT7fr7e8FoADiUqVEiasSJmVlubm5McTOzTz75xBn/6U9/KnN8o1GUKIqccd94mnjs2rXLGfeNTFHHlpWVJXOWLl3qjA8cOFDmqOerqqqSOa1atZLb9ie+8QMAAAgEhR8AAEAgKPwAAAACQeEHAAAQCAo/AACAQCREqgXm2w/0dNEcaOrYfC9NdeSoxZrNdMdvZmamzElOTnbGmzRpInNSU1Od8ZUrV8oc1cG8adMmmaO6dz/++GOZo8TTZVUf1Mdjq8/XGhCvkK819Znue09OP/10Z/y///2vzFmxYkVMxwW/Nm3ayG29e/d2xqdPny5z1M97+/btsR3Yd/iua41v/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgdjrcS4AAAA4uPGNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgaDwc5g0aZIlJCTU/K9Ro0ZWUFBgV1xxha1atSrm50tISLBx48bV/PvNN9+0hIQEe/PNN+vuoIEALViwwK644gpr166dJScnW3p6uvXq1cvGjx9vmzZt2if7fO+992zcuHFWUlKyT54fqE/mzJljZ599trVp08aSkpIsLy/P+vXrZ2PHjq15TGFhoQ0bNuw7nyvWe9/TTz9tv//97+M8cigUfh4TJ060WbNm2WuvvWajR4+2Z555xo4//ngrKys70IcGBO8vf/mL9e7d2+bOnWs/+9nPbPr06fbCCy/YeeedZw8//LBdddVV+2S/7733nt15550Ufjjkvfzyy9a/f3/bunWrjR8/3mbMmGEPPPCADRgwwCZPnhzz8/Xq1ctmzZplvXr12qvHU/jtG40O9AHUZ927d7ejjz7azMxOPPFE27Vrl9111102ZcoUu/jiiw/w0e07FRUVlpycbAkJCQf6UACnWbNm2TXXXGNDhgyxKVOmWFJSUs22IUOG2NixY2369OkH8AiBg9/48eOtXbt29uqrr1qjRv8rFy688EIbP358zM+XmZlpffv2/c7HlZeXW2pqaszPj73DN34x2H3CFhUV2aBBg2zQoEF7PObyyy+3wsLCuJ7/xRdftH79+llqaqplZGTYkCFDbNasWTXbp0yZYgkJCfb666/vkfvQQw9ZQkKCLViwoCb2wQcf2FlnnWXZ2dmWnJxsRx11lD377LO18nb/WnvGjBl25ZVXWrNmzSw1NdUqKyvjeg3A/vDrX//aEhIS7M9//nOtom+3xo0b21lnnWVmZtXV1TZ+/Hjr0qWLJSUlWfPmze2yyy6zlStX1sp57bXXbPjw4VZQUGDJycnWsWNHGzNmjG3cuLHmMePGjbOf/exnZmbWrl27mj8H4c82cCgqLi623NzcWkXfbg0a7Fk+TJ8+3Xr16mUpKSnWpUsXe/zxx2ttd/2q9/LLL7f09HRbuHChDR061DIyMmzw4ME2aNAge/nll62oqKjWn17h+6Pwi8Hnn39uZmbNmjWr8+d++umnbfjw4ZaZmWnPPPOMPfbYY7Z582YbNGiQvfPOO2ZmNmzYMGvevLlNnDhxj/xJkyZZr169rGfPnmZmNnPmTBswYICVlJTYww8/bFOnTrUjjzzSLrjgAps0adIe+VdeeaUlJibak08+af/4xz8sMTGxzl8jUBd27dplb7zxhvXu3dtat279nY+/5ppr7Oabb7YhQ4bYiy++aHfddZdNnz7d+vfvX6uo++KLL6xfv3720EMP2YwZM+z222+3OXPm2HHHHWdVVVVmZvbDH/7QrrvuOjMze/75523WrFkx/eoKOJj069fP5syZY9dff73NmTOn5jpwmT9/vo0dO9ZuvPFGmzp1qvXs2dOuuuoqe/vtt79zPzt27LCzzjrLTjrpJJs6dardeeed9qc//ckGDBhgLVq0qLnOvvlFCL6HCHuYOHFiZGbR7Nmzo6qqqqi0tDSaNm1a1KxZsygjIyNau3ZtNHDgwGjgwIF75I4aNSpq27ZtrZiZRXfccUfNv2fOnBmZWTRz5swoiqJo165dUX5+ftSjR49o165dNY8rLS2NmjdvHvXv378m9tOf/jRKSUmJSkpKamKLFy+OzCx68MEHa2JdunSJjjrqqKiqqqrWsQwbNixq2bJlzX52v9bLLrss1rcJOCDWrl0bmVl04YUXfudjlyxZEplZdO2119aKz5kzJzKz6Oc//7kzr7q6OqqqqoqKiooiM4umTp1as+23v/1tZGbR8uXLv9frAOq7jRs3Rscdd1xkZpGZRYmJiVH//v2je+65JyotLa15XNu2baPk5OSoqKioJlZRURFlZ2dHY8aMqYl9+94XRV/fM80sevzxx/fY/xlnnLHH/RTfH9/4efTt29cSExMtIyPDhg0bZi1atLB//etflpeXV6f7+fTTT2316tV26aWX1vr6PD093c4991ybPXu2lZeXm9nX38xVVFTU+sPaiRMnWlJSko0cOdLMvv5m8pNPPqn5O8SdO3fW/O/000+3NWvW2KefflrrGM4999w6fU1AfTBz5kwz+/rXSd907LHHWteuXWv92cT69evtRz/6kbVu3doaNWpkiYmJ1rZtWzMzW7JkyX47ZqC+yMnJsf/85z82d+5cu/fee2348OG2dOlSu/XWW61Hjx61vjE/8sgjrU2bNjX/Tk5Otk6dOllRUdFe7Yt70P5Dc4fHX//6V+vatas1atTI8vLyrGXLlvtkP8XFxWZmzufPz8+36upq27x5s6Wmplq3bt3smGOOsYkTJ9rVV19tu3btsqeeesqGDx9u2dnZZma2bt06MzO76aab7KabbnLu85sXrNo3UB/l5uZaamqqLV++/Dsf+13X1u6bUnV1tQ0dOtRWr15tt912m/Xo0cPS0tKsurra+vbtaxUVFXX7IoCDyNFHH13T6FhVVWU333yzTZgwwcaPH1/T5JGTk7NHXlJS0l5dO6mpqZaZmVm3Bw2Jws+ja9euNSf7tyUnJ9uWLVv2iH+7oNobuy+YNWvW7LFt9erV1qBBA8vKyqqJXXHFFXbttdfakiVLbNmyZbZmzRq74oorarbn5uaamdmtt95q55xzjnOfnTt3rvVv/mgWB4uGDRva4MGD7V//+petXLnSCgoK5GO/eW19+3GrV6+uuVYWLVpk8+fPt0mTJtmoUaNqHrP773oBfC0xMdHuuOMOmzBhgi1atKhOnpP7z/7Fr3rjVFhYaEuXLq3V/VpcXGzvvfdezM/VuXNna9WqlT399NMWRVFNvKyszP75z3/WdPrudtFFF1lycrJNmjTJJk2aZK1atbKhQ4fWer7DDjvM5s+fX/Nfat/+X0ZGRpyvHDjwbr31VouiyEaPHm07duzYY3tVVZW99NJLdtJJJ5mZ2VNPPVVr+9y5c23JkiU2ePBgM/vfjefbHcKPPPLIHs+9+zF8C4hDnevLCLP//elDfn7+Pt3/3n5jiNjwjV+cLr30UnvkkUfskksusdGjR1txcbGNHz8+rq+rGzRoYOPHj7eLL77Yhg0bZmPGjLHKykr77W9/ayUlJXbvvffWenzTpk3t7LPPtkmTJllJSYnddNNNe7TWP/LII3baaafZKaecYpdffrm1atXKNm3aZEuWLLEPP/zQnnvuue/1+oEDaXf37bXXXmu9e/e2a665xrp162ZVVVU2b948+/Of/2zdu3e3F154wa6++mp78MEHrUGDBnbaaafZihUr7LbbbrPWrVvbjTfeaGZmXbp0sQ4dOtgtt9xiURRZdna2vfTSS/baa6/tse8ePXqYmdkDDzxgo0aNssTEROvcuTP/MYVDzimnnGIFBQV25plnWpcuXay6uto++ugju//++y09Pd1uuOGGfbr/Hj162PPPP28PPfSQ9e7d2xo0aCB/C4cYHODmknppd6fr3LlzvY974oknoq5du0bJycnR4YcfHk2ePDmurt7dpkyZEvXp0ydKTk6O0tLSosGDB0fvvvuuc98zZsyo6bRaunSp8zHz58+Pzj///Kh58+ZRYmJi1KJFi+ikk06KHn744ZhfK1AfffTRR9GoUaOiNm3aRI0bN47S0tKio446Krr99tuj9evXR1H0ddf8b37zm6hTp05RYmJilJubG11yySXRV199Veu5Fi9eHA0ZMiTKyMiIsrKyovPOOy/68ssv97h+oyiKbr311ig/Pz9q0KCB81oGDgWTJ0+ORo4cGR122GFRenp6lJiYGLVp0ya69NJLo8WLF9c8rm3bttEZZ5yxR/63p1+ort60tDTn/jdt2hSNGDEiatq0aZSQkBBRstSNhCj6xu8WAQAAcMjib/wAAAACQeEHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAjEXq/cEcpaet9eAeObqqurnfEuXbrInNtuu80Z3759u8xp1aqVM66WzzGzWmv17q2GDRs647t27Yr5uQ5W9XGMZSjXms/hhx/ujB9xxBEyZ8OGDc74pk2bZM43l0L8pv79+8ucFi1aOOOrV6+WOffdd5/cFgqutT3tXkva5fLLL3fGfefzxIkTv+8hHRR8Pzd1D/fd19Tnytlnny1zpk+f7ozPnj1b5uwv33Wt8Y0fAABAICj8AAAAAkHhBwAAEAgKPwAAgEDsdXNHfab+0NPXqKH+0FM1cPiMGDFCbispKXHGGzXSb71q4khLS5M511xzjTP+0EMPyRz1Hvj+cFZti+d9w8FHXVPx/PwXLlwot6lzvaqqSua0b9/eGfdda8rKlSvltoqKCmc8OTlZ5lx88cXO+MCBA2XO1q1b5TYcGoqLi+W2r776yhnPy8uTOfE07KnP9PrYjLM34vksateunTO+efNmmeP7/Krv+MYPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABCIejfOJZ7WcrUtnjVne/bsKbcNGDDAGVfripqZbdu2zRn3rdWbkpLijJeWlsqcvn37OuO+9+Cf//ynM+4bMaDea98ImIN1LAD2VJc/S7UmtZnZggULnHHfSCO1Vm55ebnMUa8nKytL5qhzfc6cOTLnhBNOcMbvvvtumXPdddfJbTj0qbWnfdfNkCFDnHG1rmy84hmhFs+YlXg+b1SObwxOy5YtnXHfSKWysrLYDqwe4Rs/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAhEvevqrcuuwfPOO09u69GjhzPepk0bmfP555874x999JHMyc7OdsbVYtpmZps2bXLG165dK3NU52JBQYHMmTBhgjO+bNkymTNx4kRnvKioSOYcaouAhyyen9kZZ5zhjPsWQFdddpWVlTJHXQMtWrSQOU2aNHHGKyoqZM7KlSud8ebNm8ucpUuXOuOFhYUyZ9CgQc74m2++KXNw6FDnoJoUYaavG5+67JyNZ5JGPOI55j59+shtaspGampqzPs5GPCNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEAnRXvZFq5EcdU0t8uxb4Pmaa65xxvPz82WOWmB5586ddXpsO3bscMarqqpkTmJiotympKSkOOPx/NyaNm0qt6lRAo8++qjMUWNo6npB73jUx5Ey++taq0tjxoyR22644QZnfN26dTInPT3dGfeNTCkuLnbGk5KSZI76jPCNaFIjZXzXdGlpaczHpkZz/PGPf5Q5f/vb3+S2A41rLTaDBw92xvv16ydzVqxY4YyXlJTInIyMDGe8USM97U19dqv7qpm+Pn33G3W9b926VeY0btzYGU9OTpY56vV07NhR5owdO9YZ951T++sa+K798I0fAABAICj8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAARCt+0cIPF0c7Zt2zbm51KLL/sWgVcdv77up4YNGzrj8XQY+bqF4nnfMjMznXHfe5CVleWMX3HFFTLnnnvuie3AcNC5+OKL5bZVq1Y5474OetU97lsEXl0DvpzFixc740cccYTMWb9+vTO+YcMGmaO67NTrNDP76quvnPFTTjlF5tTnrl7ERnXiqnuXmVmzZs2c8by8PJmzceNGZ1zdH8zMNm/e7Iz7rhvV9f7ZZ5/JHNWh63sPfPdWRd3DfZMHlPrYvf5tfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAhEvRvnonTu3Flua9KkiTO+ZcsWmRPP4txqzIqvfds3SiJWvpEtamyM79jUOI20tDSZk5KSEtP+feIZQYMD6+yzz3bG1XlhZlZRUeGM+65BNa5BLfRupq813yLw6jPinXfekTlqnItvP+o69F036vMmPT1d5rRs2dIZX7NmjcxB/aTOdTXmx0z//Hv27ClzMjIynPFXXnlF5rRv394ZX716tcxp166dM56bmytz1JgV37U2YMAAZ9w3muWLL75wxn2v52DGN34AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEIiDpqu3e/fucpvqfvMt1qxyfJ3A8XSuqq4kX7et2qaO2cxsx44dsR2Y6U5M3wLYqnMyKytL5qguRN8C9aifDj/8cGdcLaZupq8bX1dv8+bNnfHly5fLHHXd+K6NyspKZzwpKUnmqG2+blvVoenrTlSfHb5u+E6dOjnjdPUefEaMGOGMZ2Zmyhz183/55ZdlzsaNG53x7OxsmaOuKd/5vGrVKrlN2b59uzNeUlIic5588kln/JxzzpE5eXl5zri6Bs3054D6TKlP+MYPAAAgEBR+AAAAgaDwAwAACASFHwAAQCAo/AAAAAJB4QcAABCIg2aci1rg2UyPGCkoKJA5avSDb1xEWlqa3Kaolm91zGb+MReKGl2j2uF9+/G9TjVKwref/Px8Z3zp0qUyB/WTGs3iG2GgxgP5Rhqp5/ONVFLXlG8kQzx27tzpjPuuATX+Qo2RMNOjpXxjndq0aSO3of5p1qyZ3KbGqfg+n//+97/HfAzx3G82b97sjG/dulXm1OV16BsfVVVV5YxPnTpV5vTp08cZV+OrzMwGDhzojM+YMUPm1Bd84wcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgThounpbt24tt6lOP18n8FNPPeWMqw5UM93R6lvQXfF19SYmJjrjvm4+xdex1aRJE2e8RYsWMkd1GvpeT+fOnZ1xunoPPj179nTGfT9/1Z24cuVKmaPO23i6+XydwPFQXcoqbqY/I7KysmSOek/Xr18vcwoLC+U21D+dOnWKeduGDRtkTocOHZxx1Ylupu9rvu5hdR2q5/LxHZuaVlFaWipzmjZt6oz7uorVNt/12bx5c7mtvuMbPwAAgEBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAIA6acS6ZmZlymxqjoMY7mJlNmDDBGf/HP/4hc9TC8b42cbVodVlZmcxRox987fVqBEz79u1lzrhx45xx38LUF1xwgTO+cOFCmVNQUCC34eCiRiX4xgapkQzquczMKioqnHHfNa3247s+U1JSYnouM/05UFJSInPU55fv9agxNOqYzQ7uERMhevfdd+W2888/3xn3jTTKyclxxn3njBrR5RvNoq6p8vJymaOuKd+YMnUM6nWa6Xuh75revn27M64+h8zMnnnmGbmtvuMbPwAAgEBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIRL3r6lWdbL5FmfPz851x1R3rozqCfHydTKorybegezzHoN63KIpifq5p06bJbaNHj3bGfZ1ZauFwHHzUouW+7lTV8eu7Pjdt2uSM+zrz1Dno6zhW23zXjbo+fftZv369M96tWzeZozoKfV3K8XzmoX6aO3euM3766afLnJ07dzrjq1atkjnqfPKdZ+pc902eUOemOmYzPRXDd49UtUJ2drbMyc3NdcZ9Xde7du2S2+o7vvEDAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgEBQ+AEAAASi3o1zadeunTPuG+PQrFkzZ3z16tUx79+30LpaHNs3ykKNc/G1yqsc3+LcqrXcN5ZCtb1/+umnMkcdg2+MhBq3g4NPZmamM75hwwaZo65dNbLFTI9I8n0OxLp/M/+1q6jxE75xLmrcko8a+bR582aZk5GREfN+UD9NnjzZGR8xYoTMWbdunTOek5Mjc9T14RsB43s+Zfv27THnqPuNGr9ipu+txcXFMkeNgvLlHMz4xg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAlHvunrVQsqq68ZMLxzvW2BZKSsrk9tU95NvsWbfcddljm+h6/2R06RJE5mzZs0aZ1z93Mz8nYs4cFSXuO+cVR2tvo5z1SXuWwRePZ+vq1cdd0pKisxR17uvU3/Hjh0x56iF6H2fN77uehxcVMf54sWLZY46b33XgOq2bdq0qcypqKhwxn3XZ3p6ujO+fv16maO6d9XkCzN9j/LlqOvTd2yKr7vf95m3P/GNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEAfNOBffmAK1cPxbb70V8/59I07UGAVfi7ZaZNonngXd1bGVlpbKHF+7vqJGsPgWzVYt8b169ZI5r7/+emwHhv1CXYe+UQmKb8SEug5915oayaDiZvr6jGdcRDx8C9ercS6+cRGFhYXf95CwH8Uz+mP27NkyZ/Dgwc6473xWY2NatmwpczZs2BDTc5np+5pvFJgad+S7BtU23xgkZd68eTHn1JeRLT584wcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgah3Xb0FBQXOuG/RdNUt5FvMOh6qK8jXuau6IH3dT6oryNeVpDqZtm3bJnPy8vLkNuWTTz5xxn0dwg0auP/7ok2bNjHvH/uer9tWdSH6uuxUR6Fa6N1Mn+uVlZUyRx2Dr3NS7Ud1E/r248tRfO+B6pT3dQ2mpaU54xkZGTLH1/mPfSueDlBfl7qairFw4UKZk56e7owXFRXJnM2bNzvjvu5h1cHumwixZcsWuU1R97xWrVrJHPWequ7lgx3f+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAlHvxrmoBZt9be+qTXz16tUx79834kSNPYhnXITv9ajxJz5qlIRvEfg+ffo440888YTM+fLLL51xNUbAxzcCBgdOPOezL0eNW/JROb6RRpmZmTHvJx45OTnOuG8sihpH5RtPoz4jfO9nWVmZM+4b64QDx3fdqJ9/VlaWzFmxYoUzPmfOHJnTvXt3Z9w3ykSdz757lxp75rtPq5yWLVvKHHXP810D6po+VPGNHwAAQCAo/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEot519aouHp+qqipnvKSkROaoriRfd+rWrVudcV+XnerM8nVzKfHsRy0ob2Z21FFHxXwMH3zwgTPeq1cvmaOOTS0OjgPLd874usQVdX36OnTj6WhUx+1bOF51IfpymjVr5owXFxfLHPW+rVy5Uua0bt1abotVPN2j2Pfiee9Hjhwpt61du9YZP+2002SO6mj1fQ6oz+7FixfLnK5duzrjixYtkjmdO3d2xouKimTO4Ycf7oz7Oo7Ly8tjei4z/2ut7/jGDwAAIBAUfgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACQeEHAAAQiHo3zqVRI/ch+UaZqFZsnxEjRjjjvnEVasSDb1SCej2+Nn415sI3YkLxLRyv3rczzzxT5ixcuDDmY1CvlTES9VNubq7cpq5D3xgmdX2UlZXJHHUN+EamNGnSxBlXo5vMzNavX++Mq+vWTI/MSEpKkjnqXE9NTZU56r32fQ5UVlbKbTi4dOrUyRn/5JNPZI66Djdu3ChzWrVq5YwfccQRMmf69OnO+PLly2VOixYtYtq/mb5HHXnkkTLn/vvvd8aHDBkic9SYqJ49e8ocxrkAAACg3qPwAwAACASFHwAAQCAo/AAAAAJB4QcAABCIetfVm5iYGFPczKx9+/Yx76dv377OuFpQ3kx32fmOzbdN8S2OrcTTNag6po4++miZ8+ijjzrjvq5r1WkWz+vEvufrTlVd7zt27JA5anH0iooKmaM6V33njOrEVR3CPr6Oc9WlvHnz5pifz9dxrI7bd635FqLHwUV1lPq6eps1a+aM+7q9n3/+eWd84MCBMmfJkiXO+OGHHy5zWrdu7YwnJyfLnJdeeskZ93XUdunSxRmfPXu2zFGTLFq2bClzDmZ8SgAAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAlHvxrmotnPfiImVK1fGvJ82bdo44yUlJTJHHYNvQXc1ekGNhPDl+BZn942fUNR73bFjR5mzZs0aZ/ywww6TOfPmzXPGfa8HB45vvIIa5+IbI6J+zqWlpTJHnZu+Y1PXp+9aU3zXtBpd4zuf1fvjGx+lRtf4xuCo98A3ZmPRokVyGw4cNZrFNzZInYMXXHCBzHnmmWec8bS0NJmjRnS98847Mueaa65xxj/66COZo+5FW7ZskTl5eXnOeGZmpsyZOXOmM37WWWfJnPPPP98Zf/bZZ2VOfcE3fgAAAIGg8AMAAAgEhR8AAEAgKPwAAAACQeEHAAAQiHrX1au6knxddp9//nnM+1Hdb77uRNUd6OsaVNt8+1HbfF2DakF3X47a5luYWnUafvbZZzInMTHRGfctHI4Dp3PnznKb+pmpTnQz3QWrOoTNdLerbz/r1693xrOysmSO+hzwnZvq2NQ1aKY7cX2fA+q68U04UNdnQUGBzKGr98Dx/SyHDBnijP/5z3+WOV26dHHG33rrLZmjuofVdWtmlp6e7oyvXr1a5qju3aOPPlrm/Oc//3HGMzIyZE5qaqozPmDAAJnzt7/9zRlft26dzOnTp48zTlcvAAAA6g0KPwAAgEBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIRL0b56JGGPjGucQzjqBNmzbO+Jdffilz1PgTtWC1mR4/4Xs9vhEPijo23yLwKsc3/kJZsWKF3Kbeg3heJ/a9Jk2ayG3FxcUx56hRJtu2bZM56nNAPZeZPp/Vc5mZlZWVOeNqJISZvqaiKIo5R72fZvr1+PajxmmUl5fLHBw4vs/A1q1bO+Nt27aVOep88t2j1JgT37V26qmnOuNqLIqZ2cqVK53xk08+WeZs2LDBGd+8ebPMUSNgOnToIHPUeBpfPVBYWCi31XfceQEAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEAdNV6+vw0h1C/mohaF9nYbQPv30U7mtZcuWzvj27dv31eHge+jYsaPcpjq0fYvNZ2ZmOuOdO3eWOarbVnXfmelF5X3Hproqk5OTZY56D9Ri92a6O3Hr1q0x78fXQa26d4cMGSJz3n77bbkN+1bv3r3ltg8++MAZX7VqlczZuHGjMz5q1CiZs3z5cmf8yCOPlDnq+vR1Kav9qOvWzKx79+7OuO/e8d577znjOTk5Mqdbt27OuO++pjr/e/bsKXMWLFggt+1PfOMHAAAQCAo/AACAQFD4AQAABILCDwAAIBAUfgAAAIGg8AMAAAhEvRvn0r59e2e8a9euMuf111+PeT+Mbalbqr3fTC+O7VtoGwfOhx9+KLede+65zrhvMXM1xmHLli0yR41r2LVrl8xp1Mj9ceYb96RGSfj2o0ZmqPErvudTo27MzIqKimLav5lZRkaGM/7qq6/KHBw4Q4cOldu++OILZ9w3lkSNKVNjUczMZs+eLbcp6rPbN9JIjT8pKSmROWo8jLrWzcwee+wxZ3zFihUyZ86cOc54ixYtZI76jFL3OzPGuQAAAGA/o/ADAAAIBIUfAABAICj8AAAAAkHhBwAAEIh619WrOpmaN28uc3wdhYrqCvJ189WlhISE/bIfnyiKnHHfQtvq/fF1TKkF6umsrp+mTJkS1zbl7LPPdsZvvvlmmbNs2TJn3NfN16RJE2c8OTlZ5qjz2XcN5ObmOuNVVVUyR31GtW3bVuZMmzbNGb/ttttkDg59lZWVctuAAQOccd/ki759+zrjvq77goICZzwxMVHm5OfnO+Oqs95MX7u+yQOLFy92xn3XmuosVp27ZvqzQ73O+oRv/AAAAAJB4QcAABAICj8AAIBAUPgBAAAEgsIPAAAgEBR+AAAAgah341xUO3hSUpLMycrKink/akH1nTt3xvxc8VCjVOqDeBabVyNbzPSYi/ow0gb7njpnjjnmGJmzatUqZ1yNkTAzy8jIcMYLCwtljhrj4Psc2LRpU8w5agSHb9SM77Xi0OAbMTJ79mxn3HeeTZ8+3Rnv2LGjzPn000+dcd8oE3XcvntxRUWFMz5v3jyZo8YqDRkyROa8+uqrzvjf//53mXPJJZc44+paN9Pjbk477TSZ88c//lFu25/4xg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAApEQ7WV76f7qwFQLHHfr1k3mzJ071xlXHXtmuluourpaH1wgGjXSzd6qo8z38zn33HOdcdW1ZmY2Y8YMua0u1cfu6vrc7VyX181FF10kt6mOwubNm8sc3wLxiuq29V0D6tgaN24sc5o2beqMZ2ZmypyXXnrJGfddN/UZ19qeVCe6mdm2bduccd95pq7Dnj17ypwPP/zQGT/iiCNkTqdOnZzx119/Xeaojt/WrVvLnDVr1jjjOTk5Mkfdo+bMmSNzUlJSnHHfe626en3v9YIFC+S2uvRd1xrf+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAArHX41wAAABwcOMbPwAAgEBQ+AEAAASCwg8AACAQFH4AAACBoPADAAAIBIUfAABAICj8AAAAAkHhBwAAEAgKPwAAgED8/1eHvjxu2d9hAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8, 8)) # 创建一个画板，大小是8*8\n",
    "cols, rows = 3, 3   # 想画10个子图来展示\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # 生成一个0-59999范围内的随机一维张量，然后变成python的数字\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]  # 找到这个随机数的图片和标签\n",
    "    figure.add_subplot(rows, cols, i)   # 在3*3的第i个位置添加一个子图\n",
    "    plt.title(labels_map[label])    # 显示这个子图的标签\n",
    "    plt.axis(\"off\") # 不打印X轴和Y轴\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")  #squeeze()去掉为1的维度，以灰度方式展示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a145f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理自己的图片数据，标签存在csv文件里面\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image # 把图片文件读取成Tensor\n",
    "\n",
    "# 继承PyTorch的Dataset基类，必须实现下面三个函数\n",
    "# Dataset解决的是第i个样本是什么，每次通过geitem返回一张图片，一个标签\n",
    "# 因此需要DataLoader\n",
    "class CustomImageDataset(Dataset):\n",
    "    # 参数分别表示：标签CSV所在文件路径，图片所在文件夹，图片预处理，标签预处理\n",
    "    # 读取标签文件变成DataFrame，保存图片路径文件夹，预处理函数\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    # 告诉DataLoader这个数据集有多少样本\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    # 取出样本\n",
    "    def __getitem__(self, idx):\n",
    "        # iloc()是pandas的索引方式，这里的img_labels是一个pandas.DataFrame，用这个索引意思是df.iloc[1, 0]df的第1行第0列\n",
    "        # 把图片路径和第idx行的第0列拼接，因为这个位置是图片名称，得到idx这张图片的路径\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # 把文件读成Tensor格式，比如彩色图就是(3, H, W)\n",
    "        # decode_image是把图片文件解码成原始的Tensor\n",
    "        # 但是对深度学习的训练不友好，简而言之，没有数据预处理\n",
    "        # 因此在下面给出数据预处理的方式，对于图片和标签\n",
    "        # 例如ToTensor就是把tensor进行类型转换，数值归一化，等操作\n",
    "        image = decode_image(img_path)\n",
    "        # 读取标签，就是第idx行的第1列，是图片标签\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        # 图片预处理，比如transform可以是ToTensor()\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        # 标签预处理\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        # 返回一个样本\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c0734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0704ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5674e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补一下深度学习的知识……\n",
    "# 首先epoch的意思是，一次epoch，模型完整的看完整个训练集一次\n",
    "# 但是模型不是一次读完全部训练集，而是每次读一个batch，然后一个batch更新一次参数，这叫做小批量更新\n",
    "# 所以对于一次epoch，训练集被拆成很多batch，模型会在一次epoch里面更新好几次参数\n",
    "# 在每一个batch里面，前向传播，计算loss，反向传播，然后更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a400ca6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2986ccca290>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataLoader不存储数据，只是动态地不断调用Dataset\n",
    "# DataLoader就是批量样本生成器\n",
    "# 一个会返回 (images_batch, labels_batch) 的迭代器\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "366ebb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是一个batch，每一行都是dataset的getitem()\n",
    "# [\n",
    "#     (img0, label0),\n",
    "#     (img1, label1),\n",
    "#     (img2, label2),\n",
    "#     (img3, label3)\n",
    "# ]\n",
    "# 在dataloader内部有default_collate机制，把列表里面相同位置的元素分别堆叠起来\n",
    "# (\n",
    "#     stack([img0, img1, img2, img3]),\n",
    "#     tensor([label0, label1, label2, label3])\n",
    "# )\n",
    "# 维度就变成\n",
    "# images.shape = (4, 1, 28, 28)\n",
    "# labels.shape = (4,)\n",
    "# 所以dataloader返回的就是(images_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1da6481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([3, 3, 8, 9, 4, 5, 0, 8, 0, 0, 6, 2, 8, 4, 4, 6, 1, 6, 2, 4, 2, 6, 5, 9,\n",
       "         6, 7, 3, 6, 0, 7, 0, 0, 3, 1, 9, 7, 7, 8, 6, 3, 9, 7, 3, 1, 4, 3, 0, 9,\n",
       "         9, 6, 7, 1, 6, 9, 7, 8, 6, 2, 7, 7, 1, 7, 9, 5])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_dataloader) # 创建一个迭代器对象，记住当前batch位置和索引顺序\n",
    "next(iter(train_dataloader)) # 取出第一个batch\n",
    "# 返回两个拼接好的tensor，每一个就是一个dataset拿出来的样本，然后一共64个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4e867da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(next(iter(train_dataloader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8343102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64个样本，灰度图1个通道，每个通道是28*28的矩阵，元素就是这个点的亮度\n",
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e40dc8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d96235b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features batch shape:torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape:torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader)) # 所以这里就是取出第一个batch\n",
    "print(f\"Features batch shape:{train_features.shape}\")\n",
    "print(f\"Labels batch shape:{train_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81aeb65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:Bag\n"
     ]
    }
   ],
   "source": [
    "img = train_features[0].squeeze()   # 这里的意思是拿到第一个样本，删除值为1的维度因为图片是二维的\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label:{labels_map[label.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbe7453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片在计算机上面的存储形式，png/jpg，是压缩的二进制数据\n",
    "# 读取图片的方式有多种：PIL是Python的图像对象，decode_image得到的是tensor\n",
    "# 这两种都没有预处理，ToTensor()的作用就是返回预处理后的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "# 这里的transform和target_transform就是对于图像和标签的变换\n",
    "# FashionMNIST的图片是PILImage格式，标签是整数\n",
    "# 通过ToTensor变成标准化后的张量，标签变成独热编码张量\n",
    "ds = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    # 内部lambda函数的意思是，先生成一个长度为10的全0张量，然后在第0维度的第y个位置把他变成1，就是独热编码的意思\n",
    "    # 外部的Lambda()是把一个函数包装成transform对象，这是torchvision的要求\n",
    "    # scatter_(dim, index, value)要求index必须是一个tensor，可以填多个位置\n",
    "    target_transform = Lambda(lambda y: torch.zeros(10, dtype = torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7932ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 标量也是张量，0维tensor\n",
    "torch.tensor(3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "756ac8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2614071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "405d84ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab786b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()\n",
       "Target transform: Lambda()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4dcc0dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4a2203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个样本的数据维度\n",
    "ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782331c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一个样本的独热编码的维度\n",
    "ds[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7afc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed36e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bed6cc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像分类的三层全连接网络，MLP多层感知机\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 这个是必写的，调用父类nn.Model的构造函数，初始化参数注册系统\n",
    "        # 定义一个展平层把(1, 28, 28) -> (784)\n",
    "        # 展平层的默认行为是，从第1维开始展平，因为第0维是样本个数batch_size\n",
    "        # 没有改变数值，只是改变形状，把三维数组按顺序排成一维向量\n",
    "        # 因为我们后面的第一个层是线性层，需要二维矩阵的输入，所以需要展平\n",
    "        self.flatten = nn.Flatten()\n",
    "        #nn.Sequential是一个顺序执行的层容器\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # 线性层，输入784（28*28）输出512\n",
    "            nn.Linear(28*28, 512),\n",
    "            # 激活函数ReLU(x) = max(0, x)\n",
    "            nn.ReLU(),\n",
    "            # 第二个隐藏层\n",
    "            nn.Linear(512, 512),\n",
    "            # 激活函数\n",
    "            nn.ReLU(),\n",
    "            # 输出层\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 展平数据(batch, 1, 28, 28) -> (batch, 784)\n",
    "        x = self.flatten(x)\n",
    "        # 经过变换输出每一类的概率，没有加上Softmax层输出的就是原始分数\n",
    "        # 原始分数不是概率，需要通过SoftMax层变成概率，这个原始分数会在后面调用\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cfc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "# bias表示加入偏执项，也就是线性模型的b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bc894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7.4605e-01, 2.6898e-01, 3.2711e-02, 2.2193e-01, 2.7641e-01,\n",
       "          4.7937e-01, 1.6686e-01, 3.5639e-01, 7.5657e-01, 5.2606e-02,\n",
       "          9.4888e-01, 7.8240e-01, 8.0013e-01, 6.1866e-01, 8.6774e-02,\n",
       "          5.0239e-01, 3.4357e-01, 3.6953e-01, 8.8873e-01, 6.0976e-01,\n",
       "          4.1938e-01, 2.4218e-02, 6.4894e-01, 5.1898e-01, 1.6920e-01,\n",
       "          3.7576e-01, 3.3372e-01, 2.9698e-03],\n",
       "         [6.7088e-01, 4.8680e-01, 7.5789e-01, 6.1486e-02, 7.5198e-01,\n",
       "          4.5396e-02, 6.5681e-01, 5.3807e-03, 8.7364e-01, 3.6660e-01,\n",
       "          9.8058e-01, 7.2313e-01, 5.0185e-01, 7.6478e-01, 5.3558e-01,\n",
       "          7.2944e-01, 9.6432e-01, 2.1248e-02, 4.7947e-01, 7.0015e-02,\n",
       "          1.3110e-01, 3.2759e-01, 4.7682e-01, 5.6984e-01, 1.4158e-01,\n",
       "          6.6278e-01, 3.2586e-01, 7.0428e-01],\n",
       "         [7.3137e-01, 8.4037e-01, 7.7467e-01, 8.4832e-01, 6.9749e-01,\n",
       "          8.8315e-01, 3.0223e-02, 2.7869e-01, 1.9040e-01, 7.4453e-01,\n",
       "          2.2532e-01, 2.1687e-01, 4.8825e-01, 6.7935e-01, 4.9380e-01,\n",
       "          3.8846e-01, 4.8191e-01, 7.2640e-01, 9.6609e-01, 9.2647e-01,\n",
       "          8.6167e-01, 7.3971e-01, 8.4021e-01, 2.7964e-03, 5.2007e-01,\n",
       "          3.1486e-01, 5.2638e-01, 6.7759e-02],\n",
       "         [7.9080e-02, 3.1057e-01, 6.8765e-01, 7.1353e-01, 4.2419e-01,\n",
       "          8.7559e-01, 3.0639e-01, 3.9122e-02, 2.3757e-02, 8.0382e-01,\n",
       "          1.5155e-01, 8.9191e-01, 2.8372e-01, 1.1312e-01, 6.1438e-01,\n",
       "          1.5171e-01, 5.2083e-01, 3.2678e-01, 8.3204e-01, 6.5645e-01,\n",
       "          6.7240e-01, 7.7288e-01, 9.3122e-01, 1.2115e-01, 2.3058e-02,\n",
       "          7.5466e-01, 8.1066e-01, 7.5097e-01],\n",
       "         [1.5302e-01, 6.5646e-01, 9.5098e-01, 8.9313e-01, 8.1002e-01,\n",
       "          3.6189e-01, 3.4949e-01, 3.1063e-01, 1.4773e-01, 8.0804e-01,\n",
       "          1.6800e-01, 7.2401e-01, 8.8379e-01, 9.7012e-01, 5.0950e-01,\n",
       "          9.9302e-01, 7.1039e-01, 9.3745e-01, 4.9453e-01, 7.3998e-01,\n",
       "          2.8523e-01, 1.3877e-01, 6.1822e-02, 9.0898e-02, 4.3644e-02,\n",
       "          4.5314e-01, 6.1041e-01, 3.8828e-01],\n",
       "         [2.3190e-01, 4.6303e-01, 2.3922e-01, 4.9132e-01, 7.2832e-01,\n",
       "          1.5694e-01, 8.9753e-01, 9.3417e-01, 7.1697e-01, 6.1340e-01,\n",
       "          2.9405e-01, 4.2090e-01, 6.7452e-01, 8.2368e-01, 9.8395e-01,\n",
       "          9.2800e-01, 8.1259e-01, 6.2858e-01, 9.1635e-01, 1.3377e-01,\n",
       "          2.7053e-01, 5.4920e-01, 9.4885e-01, 1.4271e-01, 5.1235e-02,\n",
       "          8.6016e-01, 2.6881e-03, 8.3079e-02],\n",
       "         [6.2834e-01, 8.0866e-01, 8.9678e-01, 5.5212e-01, 9.1859e-01,\n",
       "          5.8176e-01, 4.6863e-01, 1.5587e-01, 7.6969e-01, 2.4781e-01,\n",
       "          2.3216e-03, 9.0993e-02, 5.7712e-01, 6.1208e-01, 1.0334e-01,\n",
       "          3.8897e-01, 6.7679e-01, 4.3051e-02, 6.8029e-01, 3.5670e-01,\n",
       "          4.9144e-01, 2.0310e-01, 1.1927e-01, 5.7555e-01, 8.2284e-01,\n",
       "          7.5730e-01, 6.3364e-01, 1.1224e-01],\n",
       "         [2.9887e-01, 6.5002e-01, 7.0449e-01, 8.9144e-02, 4.2923e-01,\n",
       "          3.4769e-01, 1.4838e-01, 1.0075e-01, 1.0620e-01, 7.6201e-01,\n",
       "          5.4391e-01, 3.9691e-01, 5.8367e-01, 3.4316e-01, 4.4190e-01,\n",
       "          9.0404e-01, 9.8419e-01, 7.8108e-01, 5.1319e-01, 5.6518e-01,\n",
       "          2.6600e-01, 2.0896e-01, 3.7171e-01, 5.0283e-01, 6.9731e-05,\n",
       "          1.0817e-01, 4.7113e-01, 3.0920e-01],\n",
       "         [2.8831e-01, 5.0208e-02, 2.0800e-01, 9.4657e-01, 7.5821e-01,\n",
       "          5.2464e-01, 3.9036e-01, 3.5473e-01, 9.6483e-01, 9.8415e-02,\n",
       "          7.3327e-02, 9.2149e-01, 7.4005e-01, 3.4083e-01, 9.6354e-01,\n",
       "          8.5931e-01, 1.4467e-01, 2.8658e-01, 4.5731e-01, 1.6559e-01,\n",
       "          9.6061e-01, 1.4085e-01, 6.6258e-01, 6.8757e-01, 8.7618e-01,\n",
       "          2.2729e-01, 4.9842e-01, 8.5946e-01],\n",
       "         [1.3414e-01, 6.5175e-01, 7.9951e-01, 7.1521e-01, 9.7492e-01,\n",
       "          6.8475e-01, 6.1993e-01, 8.8451e-01, 7.6492e-01, 9.9944e-03,\n",
       "          2.2236e-01, 5.9682e-01, 3.2725e-02, 7.9338e-01, 8.2004e-01,\n",
       "          7.6661e-02, 8.9449e-01, 7.7251e-01, 1.5547e-01, 1.3746e-01,\n",
       "          3.6717e-01, 9.9316e-01, 4.3428e-02, 6.5964e-01, 2.3853e-01,\n",
       "          8.1192e-01, 5.9854e-02, 9.1939e-01],\n",
       "         [7.6417e-01, 9.2689e-01, 8.0704e-01, 4.7375e-01, 2.3784e-01,\n",
       "          5.8000e-02, 1.9492e-02, 4.8296e-01, 8.3468e-01, 2.6174e-01,\n",
       "          9.4307e-01, 9.4236e-01, 5.8893e-01, 3.3605e-01, 1.7128e-02,\n",
       "          9.5314e-01, 1.9253e-01, 2.6518e-01, 7.0705e-01, 3.9220e-01,\n",
       "          2.6950e-01, 7.0762e-01, 3.5158e-01, 4.8394e-01, 5.8945e-01,\n",
       "          8.6800e-01, 6.6901e-01, 4.1418e-01],\n",
       "         [3.7364e-01, 3.1957e-01, 2.0818e-01, 2.2671e-01, 4.0703e-01,\n",
       "          3.8145e-01, 7.7542e-02, 9.0330e-01, 1.0391e-01, 7.3895e-01,\n",
       "          5.0931e-01, 1.7660e-01, 7.9696e-01, 5.1576e-01, 5.5228e-01,\n",
       "          3.7615e-02, 6.7952e-01, 1.3437e-01, 3.8937e-01, 9.6129e-01,\n",
       "          9.1730e-01, 4.5004e-01, 5.2726e-01, 8.7390e-02, 3.0936e-04,\n",
       "          8.5187e-01, 4.3709e-01, 4.2658e-01],\n",
       "         [9.2373e-01, 1.7321e-01, 8.4540e-01, 8.3115e-01, 9.9849e-01,\n",
       "          1.5843e-01, 1.6775e-01, 5.2682e-01, 6.7426e-01, 9.7695e-01,\n",
       "          4.3656e-01, 2.8890e-01, 1.7763e-01, 5.1189e-01, 6.3623e-01,\n",
       "          4.1848e-01, 8.7941e-01, 6.0127e-01, 7.7915e-01, 5.5962e-01,\n",
       "          8.4564e-01, 9.8732e-01, 6.2848e-01, 4.2600e-01, 7.1347e-01,\n",
       "          7.2172e-01, 4.4167e-01, 9.9343e-01],\n",
       "         [9.2299e-01, 6.4647e-01, 4.4457e-02, 2.9699e-01, 3.1641e-01,\n",
       "          9.3751e-01, 8.3934e-01, 1.9571e-01, 9.9242e-01, 4.5848e-01,\n",
       "          9.6542e-01, 3.1080e-01, 4.4506e-02, 4.0766e-01, 1.8262e-01,\n",
       "          3.8868e-01, 7.3462e-01, 9.1123e-01, 8.1770e-01, 4.0678e-01,\n",
       "          9.4838e-01, 8.9592e-01, 6.4283e-01, 2.2410e-01, 1.6625e-02,\n",
       "          5.4126e-01, 4.3665e-01, 7.6121e-01],\n",
       "         [3.6672e-01, 6.0298e-01, 3.0109e-01, 4.0500e-01, 3.5773e-01,\n",
       "          2.3491e-01, 5.9735e-01, 1.8638e-02, 8.6153e-01, 2.3657e-01,\n",
       "          1.4241e-01, 5.0310e-01, 8.2744e-02, 7.8788e-01, 1.0852e-01,\n",
       "          7.2126e-01, 5.5561e-01, 3.4616e-01, 9.1926e-01, 8.5915e-01,\n",
       "          5.6515e-01, 6.5894e-01, 2.2058e-01, 1.9167e-01, 2.7857e-01,\n",
       "          5.9094e-01, 8.3581e-01, 6.8933e-01],\n",
       "         [3.1171e-01, 4.5601e-01, 6.8375e-01, 9.5242e-02, 4.3592e-01,\n",
       "          3.7880e-03, 4.7409e-01, 4.6263e-01, 9.1054e-01, 3.2146e-01,\n",
       "          5.5561e-01, 9.7890e-01, 1.7856e-01, 3.6805e-02, 6.5552e-02,\n",
       "          3.9576e-01, 8.6872e-01, 5.2872e-01, 3.8227e-01, 4.8327e-01,\n",
       "          6.9322e-01, 8.9813e-02, 2.8983e-01, 4.6174e-01, 1.6363e-01,\n",
       "          4.2005e-02, 2.1118e-01, 4.7259e-01],\n",
       "         [5.3664e-01, 1.1276e-01, 4.8732e-01, 4.5316e-02, 6.4557e-02,\n",
       "          8.2053e-01, 3.0722e-01, 8.7264e-01, 4.4275e-01, 9.9812e-01,\n",
       "          9.4145e-01, 9.6856e-01, 4.9038e-01, 7.9003e-01, 3.5045e-01,\n",
       "          2.0320e-01, 1.8990e-01, 7.9236e-01, 7.0213e-01, 7.4168e-01,\n",
       "          1.3451e-01, 5.7648e-01, 5.2573e-01, 2.4441e-01, 2.5162e-01,\n",
       "          8.6110e-01, 6.7177e-01, 3.0504e-01],\n",
       "         [7.3166e-01, 8.1564e-01, 7.1684e-01, 9.5827e-01, 9.8003e-01,\n",
       "          7.7116e-01, 6.9984e-01, 5.3636e-01, 2.0924e-01, 7.3077e-01,\n",
       "          8.5091e-01, 8.5671e-01, 8.1288e-01, 2.7498e-01, 7.0846e-01,\n",
       "          5.5652e-01, 1.0718e-01, 4.8795e-02, 9.7115e-01, 4.6249e-01,\n",
       "          2.5980e-01, 9.4272e-01, 7.4300e-02, 6.8570e-01, 9.0786e-01,\n",
       "          5.6111e-01, 1.2131e-01, 6.4185e-01],\n",
       "         [6.6095e-01, 7.8151e-01, 3.8697e-01, 4.0945e-01, 6.9650e-01,\n",
       "          7.8304e-01, 6.9577e-01, 3.6400e-01, 7.8602e-01, 4.4511e-01,\n",
       "          5.5585e-01, 3.8764e-01, 1.7016e-01, 9.7844e-02, 4.9839e-01,\n",
       "          5.5518e-01, 3.7556e-01, 8.1421e-01, 3.5430e-01, 7.8611e-01,\n",
       "          2.0091e-01, 4.0571e-02, 4.2953e-01, 2.7346e-01, 9.4912e-01,\n",
       "          7.4465e-01, 9.2962e-01, 3.3985e-01],\n",
       "         [5.9215e-01, 9.8625e-01, 9.6819e-02, 2.2939e-03, 3.4497e-01,\n",
       "          5.8895e-01, 6.9562e-02, 3.2577e-01, 6.7162e-01, 5.8401e-01,\n",
       "          2.9413e-01, 6.2686e-01, 4.9114e-01, 2.4314e-02, 8.1567e-01,\n",
       "          1.3506e-01, 6.7102e-02, 8.6589e-01, 6.5499e-01, 3.3309e-01,\n",
       "          4.5310e-01, 3.5383e-02, 9.5842e-01, 5.6264e-01, 8.4396e-01,\n",
       "          4.0124e-01, 5.8126e-01, 4.0158e-01],\n",
       "         [8.3591e-01, 4.2650e-01, 2.0001e-01, 8.7652e-01, 3.8379e-01,\n",
       "          4.0225e-01, 8.0753e-01, 1.8194e-01, 5.3874e-02, 3.0558e-01,\n",
       "          4.6621e-01, 5.1508e-01, 5.1249e-01, 2.9143e-01, 1.3365e-01,\n",
       "          3.9828e-01, 7.5777e-01, 1.9261e-02, 1.3121e-01, 3.2180e-01,\n",
       "          7.5808e-01, 9.3908e-01, 4.1895e-01, 7.4234e-02, 8.4577e-01,\n",
       "          7.7305e-02, 8.9925e-01, 4.5290e-01],\n",
       "         [5.9595e-01, 7.8790e-01, 8.2932e-01, 6.5467e-01, 6.5364e-01,\n",
       "          4.7949e-01, 4.8215e-01, 6.7565e-01, 7.6895e-01, 3.2671e-01,\n",
       "          9.1487e-01, 3.2618e-01, 1.8851e-01, 3.9534e-01, 1.1105e-01,\n",
       "          4.5562e-01, 9.1376e-01, 1.9089e-01, 8.1178e-01, 4.3631e-01,\n",
       "          9.5005e-01, 6.9028e-01, 6.2253e-01, 4.4730e-02, 5.9356e-01,\n",
       "          9.2990e-01, 5.9031e-01, 2.2114e-01],\n",
       "         [6.0336e-01, 4.2558e-02, 8.1299e-01, 8.0401e-01, 9.5535e-01,\n",
       "          7.8597e-02, 9.5271e-01, 7.2299e-01, 8.6272e-01, 7.1453e-01,\n",
       "          6.1829e-02, 3.5244e-01, 3.2091e-01, 7.3965e-03, 2.6742e-01,\n",
       "          5.5144e-01, 9.9554e-01, 9.5241e-01, 2.6700e-01, 2.0769e-01,\n",
       "          5.3534e-02, 2.6877e-01, 3.9412e-01, 1.5768e-01, 5.2053e-01,\n",
       "          6.7196e-01, 6.7711e-01, 9.2815e-01],\n",
       "         [4.3403e-02, 2.2239e-02, 8.5647e-01, 9.2720e-01, 7.0660e-02,\n",
       "          7.3189e-01, 1.2057e-01, 6.7324e-01, 4.0992e-01, 6.3097e-01,\n",
       "          6.8252e-01, 8.1107e-01, 7.0022e-01, 3.7133e-02, 5.9985e-01,\n",
       "          2.2989e-01, 9.0636e-02, 7.8402e-01, 9.0140e-01, 7.0902e-01,\n",
       "          5.2112e-01, 5.1133e-01, 2.4567e-01, 9.0690e-01, 9.5155e-01,\n",
       "          3.7190e-01, 8.8608e-01, 8.7717e-01],\n",
       "         [4.9123e-01, 8.6615e-01, 5.2970e-01, 3.3449e-01, 1.9651e-01,\n",
       "          9.1538e-01, 8.1811e-01, 6.8166e-01, 8.1648e-01, 4.9693e-01,\n",
       "          4.2458e-01, 4.7693e-01, 3.1931e-02, 8.2327e-01, 8.0097e-04,\n",
       "          6.3523e-01, 6.7356e-01, 3.3991e-01, 1.3510e-01, 7.8656e-01,\n",
       "          1.7195e-01, 7.2307e-01, 3.4380e-01, 8.1650e-01, 6.7312e-01,\n",
       "          1.7990e-01, 3.9686e-01, 8.6376e-01],\n",
       "         [2.3160e-01, 5.0098e-01, 2.8882e-01, 2.2247e-02, 4.6909e-01,\n",
       "          2.2945e-01, 1.7224e-01, 4.1194e-01, 5.9745e-01, 3.7473e-01,\n",
       "          4.6749e-01, 6.5059e-01, 2.1923e-01, 2.3628e-01, 6.9629e-01,\n",
       "          6.2155e-02, 9.2031e-01, 9.3453e-01, 6.9114e-01, 7.8309e-01,\n",
       "          2.2268e-02, 4.8497e-02, 3.0533e-02, 1.1739e-01, 7.5616e-01,\n",
       "          2.4909e-01, 8.9982e-01, 7.2534e-01],\n",
       "         [5.3066e-01, 1.3681e-01, 5.8821e-01, 2.3792e-01, 7.3696e-02,\n",
       "          6.1467e-01, 8.4605e-01, 4.7249e-01, 6.4985e-01, 6.6632e-01,\n",
       "          8.7744e-01, 2.1305e-01, 2.6220e-01, 3.5052e-01, 2.4836e-01,\n",
       "          2.8696e-04, 6.9976e-01, 6.4783e-01, 6.0812e-01, 2.5690e-01,\n",
       "          7.5700e-01, 1.2751e-01, 3.4678e-01, 6.6999e-01, 2.6308e-01,\n",
       "          4.1781e-01, 4.0715e-01, 4.4169e-01],\n",
       "         [5.9005e-02, 2.1200e-01, 9.0182e-01, 4.2901e-02, 5.5983e-01,\n",
       "          1.6038e-01, 8.5007e-01, 8.8757e-01, 1.3075e-01, 3.6861e-01,\n",
       "          4.5595e-01, 4.4116e-01, 8.8189e-01, 7.6426e-01, 1.5092e-01,\n",
       "          5.2437e-01, 3.0944e-01, 7.1821e-02, 3.8748e-01, 5.7968e-01,\n",
       "          8.8453e-03, 8.5795e-01, 5.2649e-01, 9.4825e-01, 3.6109e-01,\n",
       "          6.5483e-01, 9.3656e-01, 5.2003e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随意构造一个和样本相同维度的向量\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6068387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0134, -0.0481, -0.0380, -0.0510, -0.0352, -0.0391,  0.0526, -0.0187,\n",
       "          0.0215,  0.0516]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 会输出它的分数，也就是前向传播的结果\n",
    "# 现在我们一点没训练，他会用自动随机生成的参数\n",
    "logits = model(X)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a0e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1022, 0.0961, 0.0971, 0.0958, 0.0973, 0.0970, 0.1063, 0.0990, 0.1030,\n",
       "         0.1062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logits分数要经过softmax层变成概率\n",
    "# 下面的写法等价，dim=1表示在这一维做归一化\n",
    "# 因为我们的输出是(batch, 10)，dim=1的维度才是概率\n",
    "# softmax_layer = nn.Softmax(dim=1)\n",
    "# pred_prob = softmax_layer(logits)\n",
    "\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73d9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab.shape\n",
    "# 这是个一行十列的数组，但是其实一行没啥意义了现在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac6d8a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1022, 0.0961, 0.0971, 0.0958, 0.0973, 0.0970, 0.1063, 0.0990, 0.1030,\n",
       "        0.1062], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93c7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmax找最大的值所在的索引，传入1表示在dim=1这个维度\n",
    "# 因为我们的输入是(batch, 10)，值在dim=1这一维\n",
    "y_pred = pred_probab.argmax(1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "909256e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())\n",
    "print(input_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fd41658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa6ec35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8891a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU:tensor([[-0.0138, -0.0011, -0.0037,  0.0456,  0.3523,  0.5401, -0.0357,  0.0348,\n",
      "         -0.2106,  0.1855,  0.2641,  0.2732, -0.3406,  0.1666,  0.4613, -0.0436,\n",
      "         -0.1941,  0.3181, -0.0301, -0.0358],\n",
      "        [-0.0301, -0.1831, -0.2253,  0.4703,  0.3207,  0.2763, -0.3469,  0.3952,\n",
      "          0.0626,  0.4506,  0.3648,  0.5007, -0.7463,  0.1737,  0.0411, -0.0826,\n",
      "         -0.3782,  0.0880, -0.1472,  0.0630],\n",
      "        [ 0.0400, -0.1162, -0.0217,  0.6933,  0.4115,  0.2072, -0.1337,  0.0468,\n",
      "          0.3010,  0.0820,  0.1944,  0.1245, -0.3679,  0.1284,  0.0333, -0.2275,\n",
      "         -0.3942,  0.0270, -0.1574, -0.3041]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU:tensor([[0.0000, 0.0000, 0.0000, 0.0456, 0.3523, 0.5401, 0.0000, 0.0348, 0.0000,\n",
      "         0.1855, 0.2641, 0.2732, 0.0000, 0.1666, 0.4613, 0.0000, 0.0000, 0.3181,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.4703, 0.3207, 0.2763, 0.0000, 0.3952, 0.0626,\n",
      "         0.4506, 0.3648, 0.5007, 0.0000, 0.1737, 0.0411, 0.0000, 0.0000, 0.0880,\n",
      "         0.0000, 0.0630],\n",
      "        [0.0400, 0.0000, 0.0000, 0.6933, 0.4115, 0.2072, 0.0000, 0.0468, 0.3010,\n",
      "         0.0820, 0.1944, 0.1245, 0.0000, 0.1284, 0.0333, 0.0000, 0.0000, 0.0270,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU:{hidden1}\\n\\n\")\n",
    "# 这里的方式跟前面的softmax很像\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU:{hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6e51eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2039, -0.0507, -0.2089,  0.1411,  0.1569,  0.1641,  0.1267, -0.0837,\n",
       "         -0.0520, -0.1801],\n",
       "        [ 0.1637, -0.0833, -0.2358,  0.1238,  0.1152,  0.1397,  0.1145, -0.0773,\n",
       "          0.0415, -0.1397],\n",
       "        [ 0.2434, -0.1924, -0.2030,  0.1506,  0.2501,  0.0664,  0.2268, -0.1315,\n",
       "         -0.1197, -0.1712]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cef25a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1187, 0.0920, 0.0786, 0.1115, 0.1133, 0.1141, 0.1099, 0.0891, 0.0919,\n",
       "         0.0809],\n",
       "        [0.1149, 0.0898, 0.0771, 0.1104, 0.1095, 0.1122, 0.1094, 0.0903, 0.1017,\n",
       "         0.0848],\n",
       "        [0.1239, 0.0801, 0.0793, 0.1129, 0.1248, 0.1038, 0.1219, 0.0852, 0.0862,\n",
       "         0.0819]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "865d21df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure:{model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:linear_relu_stack.0.weight | Size:torch.Size([512, 784]) | Values:tensor([[-0.0004,  0.0166, -0.0162,  ..., -0.0321, -0.0206, -0.0320],\n",
      "        [-0.0067, -0.0077,  0.0292,  ..., -0.0036, -0.0297, -0.0334]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Layer:linear_relu_stack.0.bias | Size:torch.Size([512]) | Values:tensor([-0.0146,  0.0185], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Layer:linear_relu_stack.2.weight | Size:torch.Size([512, 512]) | Values:tensor([[-0.0156, -0.0092,  0.0015,  ...,  0.0139,  0.0031,  0.0341],\n",
      "        [-0.0148,  0.0360, -0.0005,  ..., -0.0180, -0.0101, -0.0206]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Layer:linear_relu_stack.2.bias | Size:torch.Size([512]) | Values:tensor([0.0212, 0.0115], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Layer:linear_relu_stack.4.weight | Size:torch.Size([10, 512]) | Values:tensor([[ 0.0042, -0.0156,  0.0281,  ..., -0.0098,  0.0260, -0.0301],\n",
      "        [-0.0318, -0.0381, -0.0201,  ...,  0.0352, -0.0367, -0.0108]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Layer:linear_relu_stack.4.bias | Size:torch.Size([10]) | Values:tensor([-0.0231, -0.0094], device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# named_parameters()只返回有参数的层\n",
    "# param是一个张量，param[:2]表示取前两行\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer:{name} | Size:{param.size()} | Values:{param[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "739ef2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动微分，大的要来了\n",
    "import torch\n",
    "\n",
    "x = torch.ones(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de1c9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.zeros(3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379bd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1452, -0.7539, -0.3193],\n",
       "        [ 1.2691,  0.0286,  0.1710],\n",
       "        [-0.9315, -0.4256,  1.2780],\n",
       "        [ 0.1712,  2.1195, -1.2309],\n",
       "        [-0.1129,  1.3521,  0.6836]], requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad表示这个是叶子参数\n",
    "# 叶子节点是，他是用户直接创建的，设置了requires_grad参数以及他不是由其他tensor运算得到的\n",
    "# 只有叶子节点会自动保存.grad，虽然PyTorch会计算所有节点的梯度，但是只存叶子节点的梯度\n",
    "# 没有grad_fn，但是有.grad存储梯度\n",
    "# .grad存储loss对这个张量的导数，并且只有requires_grad=True且是叶子节点才会保存\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e7f2b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0832, -1.3358,  0.7783], requires_grad=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.randn(3, requires_grad=True)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd2711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5411, 2.3208, 0.5824], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里你发现这个也是中间计算结果，他也有grad_fn\n",
    "# grad_fn记录这个张量是怎么计算出来的\n",
    "torch.matmul(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa696ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6243, 0.9849, 1.3607], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中间计算结果，有grad_fn，默认不保存.grad\n",
    "# 非叶子节点，存储前向传播的信息和后向传播的求导规则\n",
    "z = torch.matmul(x, w) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1806, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional是PyTorch提供的函数式接口集合\n",
    "# binary_corss_entropy_with_logits()是二分类交叉熵损失（带logits版本）\n",
    "# 这一步就是计算z和y之间的误差，返回一个误差值\n",
    "\n",
    "# 最终loss，标量，有grad_fn，因为他也是由运算产生的，反向传播也从这里开始\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b1c185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x000002981EDA0EE0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x000002981EDA0670>\n"
     ]
    }
   ],
   "source": [
    "# 对tensor做运算的时候，PyTorch会构建一个计算图\n",
    "# 对于计算图中的每个对象，都知道如何做前向计算，如何做反向求导\n",
    "# grad_fn存储反向传播的规则，也会保存前向传播时需要用于求导的中间信息\n",
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反向传播的标准形式，沿着计算图反向执行链式法则\n",
    "# 到了非叶子节点，就计算loss对这个节点的梯度，根据grad_fn\n",
    "# 这样子逐步求导，就是链式法则\n",
    "# 到了叶子节点，就把目前计算的梯度存入.grad\n",
    "# 计算图在执行一次反向传播之后会自动销毁，除非指定参数retain_graph=True\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "543098df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3247, 0.2427, 0.2653],\n",
      "        [0.3247, 0.2427, 0.2653],\n",
      "        [0.3247, 0.2427, 0.2653],\n",
      "        [0.3247, 0.2427, 0.2653],\n",
      "        [0.3247, 0.2427, 0.2653]])\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0cd7ae3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3247, 0.2427, 0.2653])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f40d1885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 只有训练过程需要跟踪梯度，其他不需要更新参数的时候可以把它关了\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fdd161ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 或者对张量使用detach()关闭\n",
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "da42025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "79b16294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数是可调节的参数，可以控制模型优化过程\n",
    "# epoch，迭代训练集的次数 - 原来根本就不叫训练次数\n",
    "# batch_size，每次训练的样本大小\n",
    "# learning_rate，学习率，更新模型参数的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5272e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 一、Epoch / Train / Test 的关系\n",
    "# ================================\n",
    "\n",
    "# 严格定义：\n",
    "# 一个 epoch = 训练集完整跑一遍（所有 batch 都训练一次）\n",
    "\n",
    "# 工程实践中：\n",
    "# 一个 epoch 通常包含：\n",
    "#   1️⃣ Train Loop（训练阶段）\n",
    "#   2️⃣ Validation/Test Loop（评估阶段）\n",
    "# 但只有训练阶段会更新参数\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 二、训练阶段发生什么？\n",
    "# ================================\n",
    "\n",
    "# 训练阶段的数据：\n",
    "# (X_train, y_train) 都是已知的\n",
    "\n",
    "# 每个 batch 的训练流程：\n",
    "# 1️⃣ forward：预测\n",
    "# 2️⃣ 计算 loss（预测 vs 真实标签）\n",
    "# 3️⃣ backward：反向传播\n",
    "# 4️⃣ optimizer.step()：更新参数\n",
    "# 5️⃣ optimizer.zero_grad()：清空梯度\n",
    "\n",
    "# 关键：\n",
    "# 训练阶段会更新参数\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 三、测试阶段发生什么？\n",
    "# ================================\n",
    "\n",
    "# 测试阶段的数据：\n",
    "# (X_test, y_test) 也是已知的\n",
    "# 但测试阶段不更新参数\n",
    "\n",
    "# 每个 batch 的测试流程：\n",
    "# 1️⃣ forward：预测\n",
    "# 2️⃣ 计算 loss（预测 vs 真实标签）\n",
    "# 3️⃣ 不 backward\n",
    "# 4️⃣ 不更新参数\n",
    "\n",
    "# 测试阶段通常写成：\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for X, y in test_loader:\n",
    "#         output = model(X)\n",
    "#         loss = loss_fn(output, y)\n",
    "\n",
    "# 关键：\n",
    "# 测试阶段只是评估模型表现，不改变模型\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 四、为什么 test 也用 batch？\n",
    "# ================================\n",
    "\n",
    "# 即使是测试集，也要用 DataLoader 分批：\n",
    "# 1️⃣ 显存限制（大数据无法一次性送入模型）\n",
    "# 2️⃣ GPU 计算更适合 batch 处理\n",
    "# 3️⃣ 代码结构统一（train_loader / test_loader）\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 五、训练 loss 和测试 loss 的区别\n",
    "# ================================\n",
    "\n",
    "# 训练 loss：\n",
    "# - 用来计算梯度\n",
    "# - 用来更新参数\n",
    "\n",
    "# 测试 loss：\n",
    "# - 只是用来评估模型泛化能力\n",
    "# - 不参与参数更新\n",
    "\n",
    "# 所以区别不是“有没有真实标签”\n",
    "# 两者都有真实标签\n",
    "# 区别是“是否更新参数”\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 六、模型到底“知道”什么？\n",
    "# ================================\n",
    "\n",
    "# 模型本质只是一个函数：\n",
    "# f(X) -> 预测值\n",
    "\n",
    "# 模型从来不“知道”标签\n",
    "# 是我们在训练流程中用标签计算 loss\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 七、一次完整 epoch 的时间线\n",
    "# ================================\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "\n",
    "#     # 训练阶段\n",
    "#     model.train()\n",
    "#     for X, y in train_loader:\n",
    "#         output = model(X)\n",
    "#         loss = loss_fn(output, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#     # 测试阶段\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in test_loader:\n",
    "#             output = model(X)\n",
    "#             loss = loss_fn(output, y)\n",
    "#             # 统计平均 loss / accuracy\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 八、层级关系总结\n",
    "# ================================\n",
    "\n",
    "# iteration = 一个 batch\n",
    "# epoch = 所有 batch 跑一遍训练集\n",
    "# 多个 epoch = 模型逐渐收敛的过程\n",
    "\n",
    "# Train Loop 负责“学习”\n",
    "# Test Loop 负责“评估”\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 九、核心理解一句话\n",
    "# ================================\n",
    "\n",
    "# 训练：算 loss + 反向传播 + 更新参数\n",
    "# 测试：算 loss + 不更新参数\n",
    "\n",
    "# epoch 是训练单位\n",
    "# test 是监控手段\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5feefd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "702a3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数loss有很多种，由任务类型决定\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ad86a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绝大多数的深度学习优化器本质都是基于梯度的优化方法\n",
    "# 通过注册需要训练的参数并传入学习率来初始化优化器\n",
    "# 1️⃣ optimizer.zero_grad()\n",
    "# 2️⃣ loss.backward()\n",
    "# 3️⃣ optimizer.step()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5900e686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4, 3, 1, 4, 8,\n",
       "         4, 3, 0, 2, 4, 4, 5, 3, 6, 6, 0, 8, 5, 2, 1, 6, 6, 7, 9, 5, 9, 2, 7, 3,\n",
       "         0, 3, 3, 3, 7, 2, 2, 6, 6, 8, 3, 3, 5, 0, 5, 5])]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(train_dataloader)\n",
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d908706e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fbe1fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "13306dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "353ee6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a9b00bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c1d1b4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.5"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "257ee8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45648f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    # 这里取的是每一个batch，因为loader不就是每次生成一个batch吗\n",
    "    # 但是一个batch，就是batch_size个样本\n",
    "    # 然后一个batch上面看不就是第一个是X，第二个是y嘛\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            # current是已经处理的样本数量\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            # tensor.item()的作用是把只包含一个元素的tensor转换成python标量\n",
    "            # 这个相当于还是按照batch计算很多loss，但是最后会取平均所以是累加\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # 不经过softmax也可以，因为这个操作不会改变最大值的位置\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c4dfa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.300554  [   64/60000]\n",
      "loss: 2.292728  [ 6464/60000]\n",
      "loss: 2.282525  [12864/60000]\n",
      "loss: 2.276519  [19264/60000]\n",
      "loss: 2.251023  [25664/60000]\n",
      "loss: 2.237540  [32064/60000]\n",
      "loss: 2.241451  [38464/60000]\n",
      "loss: 2.207907  [44864/60000]\n",
      "loss: 2.206778  [51264/60000]\n",
      "loss: 2.185869  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 2.179119 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.181988  [   64/60000]\n",
      "loss: 2.180679  [ 6464/60000]\n",
      "loss: 2.130503  [12864/60000]\n",
      "loss: 2.147573  [19264/60000]\n",
      "loss: 2.095473  [25664/60000]\n",
      "loss: 2.043420  [32064/60000]\n",
      "loss: 2.079363  [38464/60000]\n",
      "loss: 1.996834  [44864/60000]\n",
      "loss: 2.007684  [51264/60000]\n",
      "loss: 1.950126  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.942932 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.967893  [   64/60000]\n",
      "loss: 1.949277  [ 6464/60000]\n",
      "loss: 1.839012  [12864/60000]\n",
      "loss: 1.878304  [19264/60000]\n",
      "loss: 1.771626  [25664/60000]\n",
      "loss: 1.717927  [32064/60000]\n",
      "loss: 1.757651  [38464/60000]\n",
      "loss: 1.640465  [44864/60000]\n",
      "loss: 1.674562  [51264/60000]\n",
      "loss: 1.579118  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.581819 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.643322  [   64/60000]\n",
      "loss: 1.610367  [ 6464/60000]\n",
      "loss: 1.461189  [12864/60000]\n",
      "loss: 1.526701  [19264/60000]\n",
      "loss: 1.407681  [25664/60000]\n",
      "loss: 1.393752  [32064/60000]\n",
      "loss: 1.422769  [38464/60000]\n",
      "loss: 1.325244  [44864/60000]\n",
      "loss: 1.367302  [51264/60000]\n",
      "loss: 1.274317  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.289584 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.362188  [   64/60000]\n",
      "loss: 1.347369  [ 6464/60000]\n",
      "loss: 1.181683  [12864/60000]\n",
      "loss: 1.280136  [19264/60000]\n",
      "loss: 1.156076  [25664/60000]\n",
      "loss: 1.175148  [32064/60000]\n",
      "loss: 1.206729  [38464/60000]\n",
      "loss: 1.125651  [44864/60000]\n",
      "loss: 1.170845  [51264/60000]\n",
      "loss: 1.093385  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.6%, Avg loss: 1.106309 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.172690  [   64/60000]\n",
      "loss: 1.178579  [ 6464/60000]\n",
      "loss: 0.997080  [12864/60000]\n",
      "loss: 1.126985  [19264/60000]\n",
      "loss: 0.999851  [25664/60000]\n",
      "loss: 1.030209  [32064/60000]\n",
      "loss: 1.074080  [38464/60000]\n",
      "loss: 0.999196  [44864/60000]\n",
      "loss: 1.047594  [51264/60000]\n",
      "loss: 0.981703  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.989793 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.044910  [   64/60000]\n",
      "loss: 1.070247  [ 6464/60000]\n",
      "loss: 0.872389  [12864/60000]\n",
      "loss: 1.026503  [19264/60000]\n",
      "loss: 0.903409  [25664/60000]\n",
      "loss: 0.930702  [32064/60000]\n",
      "loss: 0.988333  [38464/60000]\n",
      "loss: 0.917725  [44864/60000]\n",
      "loss: 0.964423  [51264/60000]\n",
      "loss: 0.908369  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.3%, Avg loss: 0.911931 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.952778  [   64/60000]\n",
      "loss: 0.996184  [ 6464/60000]\n",
      "loss: 0.784525  [12864/60000]\n",
      "loss: 0.957066  [19264/60000]\n",
      "loss: 0.840703  [25664/60000]\n",
      "loss: 0.859878  [32064/60000]\n",
      "loss: 0.929099  [38464/60000]\n",
      "loss: 0.863644  [44864/60000]\n",
      "loss: 0.905532  [51264/60000]\n",
      "loss: 0.856761  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.857026 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.883085  [   64/60000]\n",
      "loss: 0.941604  [ 6464/60000]\n",
      "loss: 0.719960  [12864/60000]\n",
      "loss: 0.906460  [19264/60000]\n",
      "loss: 0.797205  [25664/60000]\n",
      "loss: 0.807934  [32064/60000]\n",
      "loss: 0.885185  [38464/60000]\n",
      "loss: 0.826154  [44864/60000]\n",
      "loss: 0.862036  [51264/60000]\n",
      "loss: 0.818234  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.8%, Avg loss: 0.816180 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.827925  [   64/60000]\n",
      "loss: 0.898824  [ 6464/60000]\n",
      "loss: 0.670305  [12864/60000]\n",
      "loss: 0.868109  [19264/60000]\n",
      "loss: 0.764933  [25664/60000]\n",
      "loss: 0.768766  [32064/60000]\n",
      "loss: 0.850157  [38464/60000]\n",
      "loss: 0.798769  [44864/60000]\n",
      "loss: 0.828464  [51264/60000]\n",
      "loss: 0.787797  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.784113 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f135292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ec0caa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\31062/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [01:31<00:00, 6.07MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d69faf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结构是代码来的，所以你只保存参数，你也要配合代码才能知道结构和参数\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b46b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16()  # 不提供参数，因为我们要用我们上面保存的参数\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "model.eval()\n",
    "# eval()是评估模式，train()是训练模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e833c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个就是保存模型的结构\n",
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bfcf0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth', weights_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "core_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
